{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirius-Aabhas/CS69002_9A_18CS60R55/blob/master/Execute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Toaq7ysxBmpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nu-97f-es39n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Load training vocab"
      ]
    },
    {
      "metadata": {
        "id": "q_jd1bA8osPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "with open('word_dictionary.pkl', 'rb') as f:\n",
        "    word_to_ix = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bd_AuK5Xy679",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['<UNKNOWN>']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zFi8NQaHrvFZ"
      },
      "cell_type": "markdown",
      "source": [
        "##Task1"
      ]
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))\n",
        "    \n",
        "class Model1B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))\n",
        "    \n",
        "class Model1C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))\n",
        "    \n",
        "class Model1D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 500)\n",
        "        self.lin2 = nn.Linear(500, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eXZ5oiJz3oRs"
      },
      "cell_type": "markdown",
      "source": [
        "##Task2"
      ]
    },
    {
      "metadata": {
        "id": "AC5vnfLG3s8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 10)\n",
        "        self.lin2 = nn.Linear(10, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))\n",
        "    \n",
        "class Model2B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 20)\n",
        "        self.lin2 = nn.Linear(20, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))\n",
        "    \n",
        "class Model2C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 30)\n",
        "        self.lin3 = nn.Linear(30, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))\n",
        "    \n",
        "class Model2D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))\n",
        "    \n",
        "class Model2E(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2E, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gcyPaqzo42Ea"
      },
      "cell_type": "markdown",
      "source": [
        "##Task3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kire3o2W42Ed",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model3A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "class Model3B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 100)\n",
        "        self.lin3 = nn.Linear(100, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pGje3Qmb53SB"
      },
      "cell_type": "markdown",
      "source": [
        "##Task4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1q9dRGoH53SF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "class Model4B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 100)\n",
        "        self.lin3 = nn.Linear(100,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))\n",
        "\n",
        "class Model4C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 10)\n",
        "        self.lin3 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_P3kpbn6CkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task5"
      ]
    },
    {
      "metadata": {
        "id": "WyuNEDLy6F-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "class Model5B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.tanh(self.lin1(x))\n",
        "        x = F.tanh(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.tanh(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "class Model5C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.sigmoid(self.lin1(x))\n",
        "        x = F.sigmoid(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.sigmoid(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XxKqNECsxCSU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task7"
      ]
    },
    {
      "metadata": {
        "id": "SzM0aA9fxIwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model7A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "class Model7B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))\n",
        "\n",
        "class Model7C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0IHp1itkutrt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Main code"
      ]
    },
    {
      "metadata": {
        "id": "TBhx3umWu-Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate_and_save(model, file):\n",
        "    model = model.cpu()\n",
        "    preds = []\n",
        "    for instance, label in data_test:\n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "        logprobs = model(bow_vec)\n",
        "        #print(logprobs)\n",
        "        pred = np.argmax(logprobs.data.cpu().numpy())\n",
        "        preds.append(pred)\n",
        "\n",
        "    print('accuracy: {}'.format(accuracy_score(text_labels_test, preds)))\n",
        "    print('precision: {}'.format(precision_score(text_labels_test, preds)))\n",
        "    print('recall: {}'.format(recall_score(text_labels_test, preds)))\n",
        "    print('f1-score: {}'.format(f1_score(text_labels_test, preds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHXKubc019hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('Test_5K.csv', sep='\\t')\n",
        "text_reviews_test = df_test['text'].astype(str).tolist()\n",
        "text_labels_test = df_test['label'].astype(int)\n",
        "\n",
        "text_reviews_test = [x.lower() for x in text_reviews_test]\n",
        "data_test = [(text_reviews_test[i], text_labels_test[i])for i in range(len(text_labels_test))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUpI3ps6BrwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdl = torch.load('Model7C.mdl')\n",
        "validate_and_save(mdl, 'Task1_pred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}