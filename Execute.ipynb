{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirius-Aabhas/CS69002_9A_18CS60R55/blob/master/Execute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Toaq7ysxBmpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import string\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3VpG5_h1oKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data for now"
      ]
    },
    {
      "metadata": {
        "id": "pHXKubc019hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train_20K.csv', sep='\\t')\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gpv07aqq0wJX",
        "colab_type": "code",
        "outputId": "75989697-6edd-4bc0-8c64-84f86d01febf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('Test_5K.csv', sep='\\t')\n",
        "df_test.tail()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>I don't know how to describe this movie. It's ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>I found this movie hilarious. The spoofs on ot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>My family and I have viewed this movie often o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>The Shining, you know what's weird about this ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Nobody could like this movie for its merit but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "4995  I don't know how to describe this movie. It's ...      0\n",
              "4996  I found this movie hilarious. The spoofs on ot...      1\n",
              "4997  My family and I have viewed this movie often o...      1\n",
              "4998  The Shining, you know what's weird about this ...      1\n",
              "4999  Nobody could like this movie for its merit but...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "zvXSxRtMNw8U",
        "colab_type": "code",
        "outputId": "9f00b002-5430-494f-90e8-8a5dbf4c5742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df[df['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df[df['label']==1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rbQhm8mQ7BN",
        "colab_type": "code",
        "outputId": "fcc82f46-6db3-490c-a7d8-b2ddd18e562c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "            \n",
        "text_reviews = filtered_text_reviews\n",
        "print(text_reviews[0], text_labels[0])\n",
        "print(len(text_reviews), len(text_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c1c212d6ab05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfiltered_text_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_reviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfiltered_text_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'br'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tOgBzlyA2znw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = [(text_reviews[i], text_labels[i])for i in range(len(text_labels))]\n",
        "data[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTk26HxZ6qjj",
        "colab_type": "code",
        "outputId": "93a6487e-8613-4f80-8ecd-1fed45a4a14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_test[df_test['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_test[df_test['label']==1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 2482\n",
            "Number of Positive movie reviews 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qirQBcpl60vS",
        "colab_type": "code",
        "outputId": "ff8c615b-5824-4e79-d03b-8d7f30f8136a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews_test = df_test['text'].astype(str).tolist()\n",
        "text_labels_test = df_test['label'].astype(int)\n",
        "\n",
        "text_reviews_test = [x.lower() for x in text_reviews_test]\n",
        "\n",
        "print(text_reviews_test[0], text_labels_test[0])\n",
        "print(len(text_reviews_test), len(text_labels_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as always this is an inaccurate picture of the homeless. tv told a lot of lies about panhandlers in the early 1990s and made everyone look bad, and claimed we all made over $100 a day when $20-40 a day was much closer to reality. when someone drove by where i held up a sign offering to work, and offered me work, i actually went and took the work if i was physically able.and if i would been offered the $100,000 id damned sure invested in in apt prepaid for at least 2 years, and kept most in the bank and still left myself $10-20000 for nl $1-2 and $2-5 cash games at the casinos. i usually always win and could win decent if i just had a bankroll. instead i win about $1000 a month is all playing in always minimum buying in due to not wanting to risk losing it all. i was only homeless cause i didn't wanna risk spending all my money and going broke, sometimes i had over $1000-2000 in my sock while i slept outside. anyone wanting to talk contact sevencard2003 on yahoo messenger.i admit i was different than most homeless people though, due to the fact i never drank smoke or took drugs. im no longer homeless, am now in govt housing for $177 a month and getting ssi and spend most of my time winning at online poker. mom and sunflower diversified worked hard to get me ssi. glad my days of hiding in under the stage in the convention center of the casino at night sleeping, worrying about getting caught by security are finally over. had this tv crew picked me theyd been over a lot sooner. its a shame how they don't better select who they pick. 0\n",
            "5000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "89gIvwYSx_MJ",
        "outputId": "3803dbf8-3e26-490b-99c2-b28a822dd031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "data_test = [(text_reviews_test[i], text_labels_test[i])for i in range(len(text_labels_test))]\n",
        "data_test[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"as always this is an inaccurate picture of the homeless. tv told a lot of lies about panhandlers in the early 1990s and made everyone look bad, and claimed we all made over $100 a day when $20-40 a day was much closer to reality. when someone drove by where i held up a sign offering to work, and offered me work, i actually went and took the work if i was physically able.and if i would been offered the $100,000 id damned sure invested in in apt prepaid for at least 2 years, and kept most in the bank and still left myself $10-20000 for nl $1-2 and $2-5 cash games at the casinos. i usually always win and could win decent if i just had a bankroll. instead i win about $1000 a month is all playing in always minimum buying in due to not wanting to risk losing it all. i was only homeless cause i didn't wanna risk spending all my money and going broke, sometimes i had over $1000-2000 in my sock while i slept outside. anyone wanting to talk contact sevencard2003 on yahoo messenger.i admit i was different than most homeless people though, due to the fact i never drank smoke or took drugs. im no longer homeless, am now in govt housing for $177 a month and getting ssi and spend most of my time winning at online poker. mom and sunflower diversified worked hard to get me ssi. glad my days of hiding in under the stage in the convention center of the casino at night sleeping, worrying about getting caught by security are finally over. had this tv crew picked me theyd been over a lot sooner. its a shame how they don't better select who they pick.\",\n",
              "  0),\n",
              " ('did the movie-makers even preview this before they released it? the script jumps from place to place without giving much explanation. the beginning doesn\\'t clarify if its a prequel or not. it starts with superman\\'s beginnings on earth and then jumps to a point after the last movie - but doesn\\'t really alert the viewer of this. very confusing! superman himself is weak and in need of prozac. he is portrayed as a potential home-wrecker, a stalker, and someone who is clearly depressed and confused. this type of character rarely makes for an interesting hero. the ending is absolutely ridiculous. superman ending up in a hospital just made me want to kill him off myself. i\\'m seriously waiting for a snl skit where superman appears on maury povich and maury says, \"the results are in - in the case of the child, superman, you are the father.\" to sum up - ok acting by this superman and kevin spacey, but horrible script. the movie is basically unwatchable.',\n",
              "  0),\n",
              " (\"heavily re-edited and often confusing, the original screen version of man on fire was at least ten years out of date when it was made and the passing years haven't made it any better. this is the kind of movie that producers with too much money and too little experience make to get attention and everyone else does just to pay off their outstanding alimony or their drug dealer, with scott glenn's bodyguard going out on a limb to rescue his 12-year-old charge, the kidnapped daughter of a wealthy italian family. an interesting cast - joe pesci, brooke adams, danny aiello, jonathan pryce - have all done better, the action is sluggish and sparse and only john scott's exceptionally fine score (part of which turned up in the last reel of die hard) makes a positive impression. one case where the remake (made by tony scott, the original choice of director for this version) is an improvement.\",\n",
              "  0),\n",
              " ('i notice that most of the people who think this film speaks the truth were either not born before the moon landings (1969-1972), or not old enough to appreciate them. i think it is much easier to question an historic event if you did not live through it.<br /><br />i was a youngster at the time of apollo, but i was old enough to understand what was going on. the entire world followed the moon landings. our families gathered around the tv to watch the launch. newspaper headlines screamed the latest goings-on each day, from launch to landing, from moonwalks to moon liftoff, all the way to splashdown, in a multitude of languages. in school, some classes were cancelled so we could watch the main events on tv. during apollo 13 the world prayed and held its collective breath as the men limped home to an uncertain fate. you couldn\\'t go anywhere without someone asking what the latest was. the world was truly one community. <br /><br />now with a buffer of 30-odd years after the fact, it is easy to claim fraud because worldwide enthusiasm and interest has died down. we are left with our history books, and anybody can claim that history is wrong and attempt to \"prove\" it with a bunch of lies and made-up facts while completely ignoring the preponderance of evidence showing otherwise--not to mention the proof that dwells in the souls and memories of those who lived through these wonderfully heady and fantastic days.',\n",
              "  0),\n",
              " ('first of all, this is a low-budget movie, so my expectations were incredibly low going into it. i assume most people looking at the info for this movie just wanted a bloodfest, and essentially that\\'s all it is.<br /><br />plot? there really is none. it\\'s basically saw but in china and a whole hell of a lot worse. cast? there is none, period. special effects? absolutely awful in my opinion... there were cutaways and the blood was often completely unbelievable because of amounts, splatter, color, texture, etc.<br /><br />i believe the purpose of this movie was supposed to be a brutal, shock film. now it had some great potential on a bigger budget but poor scripting, poor dialogue, awful acting, what seemed like camcorder video shots, and just plain unbelievable \"gore,\" made this movie truly awful.<br /><br />there are movies worth taking a chance against some reviews, even \"b-rate\" movies deserve some opportunities (blood trails for example was the most recent i saw against reviews that was worth it), but this was simply awful. i hope that people considering this movie read my comment and decide against it.<br /><br />i\\'m all for brutality and shock, but the overall unrealism and truly awful acting makes for an awful experience. save your time/money and chance something else, you won\\'t be disappointed.',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "zydP-RKS0GgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "COY4uTBU2OSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "    word_to_ix = {}\n",
        "    word_cntr = {}\n",
        "    word_set = set()\n",
        "    #print(dataset)\n",
        "    for sent in dataset:\n",
        "        for word in sent.split():\n",
        "            if word not in word_cntr:\n",
        "                word_cntr[word] = 1\n",
        "            else:\n",
        "                word_cntr[word] += 1\n",
        "    \n",
        "    for word in word_cntr:\n",
        "        if word_cntr[word] >= 5:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "            \n",
        "    word_to_ix['<UNKNOWN>'] = len(word_to_ix)\n",
        "        \n",
        "    return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXGW8ypdRXsQ",
        "colab_type": "code",
        "outputId": "ffe09002-06dc-4817-f4e4-cafadb690ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = generate_word_ids(text_reviews + text_reviews_test)\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-54240f96926c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_to_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_word_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_reviews\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext_reviews_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text_reviews' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oMvJ_navH33k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "92ad1d22-8952-457d-c80a-d3b372327a76"
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = np.load('word_dict.npy')\n",
        "word_to_ix[0]\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1c86b8dc2873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_to_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word_dict.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd_AuK5Xy679",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['<UNKNOWN>']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n7XiuOLoWQlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "features = make_bow_vector(text_reviews[0], word_to_ix).to(device)\n",
        "for i in range(1,len(text_reviews[:7000])):\n",
        "    vec = make_bow_vector(text_reviews[i], word_to_ix).to(device)\n",
        "    features = torch.cat((features,vec)).to(device)\n",
        "    if i%1000 == 0:\n",
        "        print(time.time() - t1)\n",
        "        t1 = time.time()\n",
        "        print(features.shape)\n",
        "targets = torch.tensor(text_labels[:7000], dtype=torch.int).to(device)\n",
        "\n",
        "print(time.time() - t1)\n",
        "print(features.shape)\n",
        "print(targets.shape)\n",
        "train = data_utils.TensorDataset(features, targets)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=16, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6T21S6moBrZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(model):\n",
        "    model = model.cpu()\n",
        "    preds = []\n",
        "    for instance, label in data_test:\n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "        logprobs = model(bow_vec)\n",
        "        #print(logprobs)\n",
        "        pred = np.argmax(logprobs.data.cpu().numpy())\n",
        "        preds.append(pred)\n",
        "\n",
        "    print('accuracy: {}'.format(accuracy_score(text_labels_test, preds)))\n",
        "    print('precision: {}'.format(precision_score(text_labels_test, preds)))\n",
        "    print('recall: {}'.format(recall_score(text_labels_test, preds)))\n",
        "    print('f1-score: {}'.format(f1_score(text_labels_test, preds)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUpI3ps6BrwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdl = torch.load('Model1A.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lsGPKIRBuHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "288c1ca5-978d-45e8-9ffd-e38c06ab8e49"
      },
      "cell_type": "code",
      "source": [
        "validate(mdl)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-66b9150e85d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-6006e8afdffa>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbow_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_bow_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(logprobs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_bow_vector' is not defined"
          ]
        }
      ]
    }
  ]
}