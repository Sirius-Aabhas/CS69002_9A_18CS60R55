{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirius-Aabhas/CS69002_9A_18CS60R55/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bRuGSGqnMOXz",
        "colab_type": "code",
        "outputId": "cf22b8f9-ca9a-4332-c897-ca8d73453477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "device = torch.device('cuda:0')\n",
        "device"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {
        "id": "ijrEth3MRQ6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data"
      ]
    },
    {
      "metadata": {
        "id": "J5ITVAYmiy5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQLFDGIQjrh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Train_20K.csv'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7sqK9HKoGzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3VpG5_h1oKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data for now"
      ]
    },
    {
      "metadata": {
        "id": "pHXKubc019hc",
        "colab_type": "code",
        "outputId": "a20a2359-7b17-4e58-a039-f6547488f6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train_20K.csv', sep='\\t')\n",
        "df.tail()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17994</th>\n",
              "      <td>I was pleasantly surprised by the film. Let's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>you must be seeing my comments over many films...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>This is one of those movies that they did too ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>Anyone notice that Tommy only has 3 facial exp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>I remember watching ATTACK when it first came ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "17994  I was pleasantly surprised by the film. Let's ...      1\n",
              "17995  you must be seeing my comments over many films...      0\n",
              "17996  This is one of those movies that they did too ...      1\n",
              "17997  Anyone notice that Tommy only has 3 facial exp...      0\n",
              "17998  I remember watching ATTACK when it first came ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "Gpv07aqq0wJX",
        "colab_type": "code",
        "outputId": "ade99b07-c09f-4d51-85b1-0dbef1a0b95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('Test_5K.csv', sep='\\t')\n",
        "df_test.tail()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>I don't know how to describe this movie. It's ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>I found this movie hilarious. The spoofs on ot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>My family and I have viewed this movie often o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>The Shining, you know what's weird about this ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Nobody could like this movie for its merit but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "4995  I don't know how to describe this movie. It's ...      0\n",
              "4996  I found this movie hilarious. The spoofs on ot...      1\n",
              "4997  My family and I have viewed this movie often o...      1\n",
              "4998  The Shining, you know what's weird about this ...      1\n",
              "4999  Nobody could like this movie for its merit but...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "id": "zvXSxRtMNw8U",
        "colab_type": "code",
        "outputId": "4fafc14b-7327-476b-e44a-9bb098afbe4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df[df['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df[df['label']==1]))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rbQhm8mQ7BN",
        "colab_type": "code",
        "outputId": "be4d5295-cedd-4961-e9fa-842159deafc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "\n",
        "filtered_text_reviews = []\n",
        "for sent in text_reviews:\n",
        "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
        "    word_tokens = word_tokenize(sent)\n",
        "    filtered_text_reviews.append(' '.join([w for w in word_tokens if (not w in stop_words and w != 'br')]))\n",
        "            \n",
        "text_reviews = filtered_text_reviews\n",
        "print(text_reviews[0], text_labels[0])\n",
        "print(len(text_reviews), len(text_labels))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "john waters given us genuinely enjoyable film certainly isnt without shocking watersesque moments tamer older culty stuff pink flamingoes pecker harkens back johns early mainstream stage reminds viewer kind humor evident polyester overall really fun comedy great moments 1\n",
            "17999 17999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tOgBzlyA2znw",
        "colab_type": "code",
        "outputId": "70dcc9b8-262b-48c4-d3f7-9b0d81b89043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "data = [(text_reviews[i], text_labels[i])for i in range(len(text_labels))]\n",
        "data[:5]"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('john waters given us genuinely enjoyable film certainly isnt without shocking watersesque moments tamer older culty stuff pink flamingoes pecker harkens back johns early mainstream stage reminds viewer kind humor evident polyester overall really fun comedy great moments',\n",
              "  1),\n",
              " ('first two seasons comedy series strange werent funny drama element bill mother struggling usual problems life element bit depressing didnt mix well th comedy elements probably dropped soon became one funniest comedy series bbc ever made chemistry bill bens characters funny always many brilliant memorable sketches series christmas specials hilarious real treat christmas show came stop main actor gary olsen playing bill passed away sad brilliant actor films n funny man ripbr underrated show sadly disappeared television screens doesnt repeated often though appear uktv gold repeated bbc one two show brilliant comedy new audience',\n",
              "  1),\n",
              " ('unfortunate mess shiner wanted like overthetop antifilm aspirant fact found number moments powerful resonance sadly moments far appreciate calson attempting advantage aspired bare bones budget cinematography destroyed truly atrocious editing benefited movie allbr bad acting abounds low budget big budget cinema shiner remarkably bad performances nearly painful watch particular straight couple linda young guy two poorly written characters offering almost nothing story acting abysmal neither actor seems capable resisting smirking cracking drearily drop lines appalling lack skill choppy editing almost lends feeling roles entirely gratuitous dropped avoid films stereotypically cast oddball gay film would better suchbr going wrong several performances seem capture calson hoping get particular story centering bob tim two richly drawn characters offer rewards genuinely captivating performances nicholas king bob david zelinas tim tim boxer serious issues remarkably low self esteem disguised almost cartoon like arrogance wears like armour plating obsessed tim seemingly harmless yet ultimately creepy bob stalks boxer classic catandmouse fashion tables turned hunter becomes hunted resulting films genuine emotional catharsis film artificially hardedged thats compliment one character must revelatory break breakdown case proves final confrontation bob tim provide zelinas king opportunity display real acting chopsbr played scott stepp derris nile tony danny seem focus movie despite bravado moments including one truly disturbing scene revealing sexviolence obsession cant seem escape cartoonlike artifice difficult look beyond seeming one note symphony find anything obviousbr ultimately raw material could used tell story better fashion alas really isnt much recommend yet performances messrs king zelinas really offer something special glimpse might ultimately worth seeing',\n",
              "  0),\n",
              " ('im entirely sure rob schmidt qualifies master genre horror since previously directed one horror film called wrong turn one actually slightly mediocre fact made right die one best creepiest episodes entire second season masters horror franchise similar underdog story season one william malone made best episodes fair haired child even though long feature films fear dot com house haunted hill sucked pretty badlybr story right die cleverly picks nowadays piping hot social debate euthanasia thankfully also features multiple oldfashioned horror themes like ghostly vengeance murderous conspiracies pitch black humor comic book styled violence whilst driving home late one night discussing husbands continuous adultery addison couple involved terrible car accident cliff walks away wreck unharmed wife abby fully burned needs kept alive artificially whilst cliff sleazy attorney corbin bernsen dentist want plug plug sue car constructor abbeys mum sets giant media campaign keep daughter alive vegetable blame everything cliff meanwhile abbeys hateful spirit comes back revenge kills someone cliffs surrounding whenever near fatal experience medical devices victims cliff realizes might safer keep wife alive wants remain alive well right die stupendous episode exactly type stuff always hoped see tvseries concept like masters horror violent gory sick twisted sense humor loads sleaze sequences euthanasia theme whole obligatory media circus surrounds processed script well yet without unnecessarily reverting political standpoints morality lessons atmosphere suspenseful killing sequences suitably nasty unsettling actresses julia anderson robin sydney pretty face impressively voluptuous racks always welcome plus corbin bernsen finally offered chance depict meanspirited egocentric bastard great moh episode definitely one highlights seasons',\n",
              "  1),\n",
              " ('wasnt sure whether laugh cry porretta good looking resembled like mexican porn star english outlaw costumes costumes tshirt strips black leather marions clothesor lack themthat really got fans stinker really believe women dressed like medieval england mongols vikings inaccurate stupid episode alien worst especially make mainly consisted oatmeal facean old trickthe hedgehog monster pretty funny climbing side castle ladder arrowsas us accents grated initial drawling voice rawbin hood liddle johnthe second robin marion really quite minging looks left show went totally pan',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "metadata": {
        "id": "0V2GnN9Z6Yj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwEQFKUT6cc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Test_5K.csv'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qs2rHjSN6k2b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.csv'].decode('utf-8')), sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTk26HxZ6qjj",
        "colab_type": "code",
        "outputId": "8683c5cb-4f19-4947-e42a-508c863c9940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_test[df_test['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_test[df_test['label']==1]))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 2482\n",
            "Number of Positive movie reviews 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qirQBcpl60vS",
        "colab_type": "code",
        "outputId": "a5f11538-e845-4a5f-8c53-a4fd5bded0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews_test = df_test['text'].astype(str).tolist()\n",
        "text_labels_test = df_test['label'].astype(int)\n",
        "\n",
        "text_reviews_test = [x.lower() for x in text_reviews_test]\n",
        "\n",
        "filtered_text_reviews = []\n",
        "for sent in text_reviews_test:\n",
        "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
        "    word_tokens = word_tokenize(sent)\n",
        "    filtered_text_reviews.append(' '.join([w for w in word_tokens if (not w in stop_words and w != 'br')]))\n",
        "            \n",
        "text_reviews_test = filtered_text_reviews\n",
        "\n",
        "print(text_reviews_test[0], text_labels_test[0])\n",
        "print(len(text_reviews_test), len(text_labels_test))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "always inaccurate picture homeless tv told lot lies panhandlers early 1990s made everyone look bad claimed made 100 day 2040 day much closer reality someone drove held sign offering work offered work actually went took work physically ableand would offered 100000 id damned sure invested apt prepaid least 2 years kept bank still left 1020000 nl 12 25 cash games casinos usually always win could win decent bankroll instead win 1000 month playing always minimum buying due wanting risk losing homeless cause didnt wan na risk spending money going broke sometimes 10002000 sock slept outside anyone wanting talk contact sevencard2003 yahoo messengeri admit different homeless people though due fact never drank smoke took drugs im longer homeless govt housing 177 month getting ssi spend time winning online poker mom sunflower diversified worked hard get ssi glad days hiding stage convention center casino night sleeping worrying getting caught security finally tv crew picked theyd lot sooner shame dont better select pick 0\n",
            "5000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "89gIvwYSx_MJ",
        "outputId": "5eda877d-56af-4c02-cb75-59340f5adb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "data_test = [(text_reviews_test[i], text_labels_test[i])for i in range(len(text_labels_test))]\n",
        "data_test[:5]"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('always inaccurate picture homeless tv told lot lies panhandlers early 1990s made everyone look bad claimed made 100 day 2040 day much closer reality someone drove held sign offering work offered work actually went took work physically ableand would offered 100000 id damned sure invested apt prepaid least 2 years kept bank still left 1020000 nl 12 25 cash games casinos usually always win could win decent bankroll instead win 1000 month playing always minimum buying due wanting risk losing homeless cause didnt wan na risk spending money going broke sometimes 10002000 sock slept outside anyone wanting talk contact sevencard2003 yahoo messengeri admit different homeless people though due fact never drank smoke took drugs im longer homeless govt housing 177 month getting ssi spend time winning online poker mom sunflower diversified worked hard get ssi glad days hiding stage convention center casino night sleeping worrying getting caught security finally tv crew picked theyd lot sooner shame dont better select pick',\n",
              "  0),\n",
              " ('moviemakers even preview released script jumps place place without giving much explanation beginning doesnt clarify prequel starts supermans beginnings earth jumps point last movie doesnt really alert viewer confusing superman weak need prozac portrayed potential homewrecker stalker someone clearly depressed confused type character rarely makes interesting hero ending absolutely ridiculous superman ending hospital made want kill im seriously waiting snl skit superman appears maury povich maury says results case child superman father sum ok acting superman kevin spacey horrible script movie basically unwatchable',\n",
              "  0),\n",
              " ('heavily reedited often confusing original screen version man fire least ten years date made passing years havent made better kind movie producers much money little experience make get attention everyone else pay outstanding alimony drug dealer scott glenns bodyguard going limb rescue 12yearold charge kidnapped daughter wealthy italian family interesting cast joe pesci brooke adams danny aiello jonathan pryce done better action sluggish sparse john scotts exceptionally fine score part turned last reel die hard makes positive impression one case remake made tony scott original choice director version improvement',\n",
              "  0),\n",
              " ('notice people think film speaks truth either born moon landings 19691972 old enough appreciate think much easier question historic event live itbr youngster time apollo old enough understand going entire world followed moon landings families gathered around tv watch launch newspaper headlines screamed latest goingson day launch landing moonwalks moon liftoff way splashdown multitude languages school classes cancelled could watch main events tv apollo 13 world prayed held collective breath men limped home uncertain fate couldnt go anywhere without someone asking latest world truly one community buffer 30odd years fact easy claim fraud worldwide enthusiasm interest died left history books anybody claim history wrong attempt prove bunch lies madeup facts completely ignoring preponderance evidence showing otherwisenot mention proof dwells souls memories lived wonderfully heady fantastic days',\n",
              "  0),\n",
              " ('first lowbudget movie expectations incredibly low going assume people looking info movie wanted bloodfest essentially thats isbr plot really none basically saw china whole hell lot worse cast none period special effects absolutely awful opinion cutaways blood often completely unbelievable amounts splatter color texture etcbr believe purpose movie supposed brutal shock film great potential bigger budget poor scripting poor dialogue awful acting seemed like camcorder video shots plain unbelievable gore made movie truly awfulbr movies worth taking chance reviews even brate movies deserve opportunities blood trails example recent saw reviews worth simply awful hope people considering movie read comment decide itbr im brutality shock overall unrealism truly awful acting makes awful experience save timemoney chance something else wont disappointed',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "zydP-RKS0GgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "COY4uTBU2OSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "    word_to_ix = {}\n",
        "    word_cntr = {}\n",
        "    word_set = set()\n",
        "    #print(dataset)\n",
        "    for sent in dataset:\n",
        "        for word in sent.split():\n",
        "            if word not in word_cntr:\n",
        "                word_cntr[word] = 1\n",
        "            else:\n",
        "                word_cntr[word] += 1\n",
        "    \n",
        "    for word in word_cntr:\n",
        "        if word_cntr[word] >= 5:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "            \n",
        "    word_to_ix['<UNKNOWN>'] = len(word_to_ix)\n",
        "        \n",
        "    return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXGW8ypdRXsQ",
        "colab_type": "code",
        "outputId": "a1bd2248-bb72-429e-f9ed-ee1c868f3974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = generate_word_ids(text_reviews + text_reviews_test)\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd_AuK5Xy679",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['<UNKNOWN>']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n7XiuOLoWQlh",
        "colab_type": "code",
        "outputId": "e677311f-060f-442b-9525-eb893e3ddc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "features = make_bow_vector(text_reviews[0], word_to_ix).to(device)\n",
        "for i in range(1,len(text_reviews)):\n",
        "    vec = make_bow_vector(text_reviews[i], word_to_ix).to(device)\n",
        "    features = torch.cat((features,vec)).to(device)\n",
        "    if i%1000 == 0:\n",
        "        print(time.time() - t1)\n",
        "        t1 = time.time()\n",
        "        print(features.shape)\n",
        "targets = torch.tensor(text_labels, dtype=torch.int).to(device)\n",
        "\n",
        "print(time.time() - t1)\n",
        "print(features.shape)\n",
        "print(targets.shape)\n",
        "train = data_utils.TensorDataset(features, targets)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=32, shuffle=True)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.024198532104492\n",
            "torch.Size([1001, 30624])\n",
            "3.3038599491119385\n",
            "torch.Size([2001, 30624])\n",
            "5.116696119308472\n",
            "torch.Size([3001, 30624])\n",
            "7.366191387176514\n",
            "torch.Size([4001, 30624])\n",
            "9.376363039016724\n",
            "torch.Size([5001, 30624])\n",
            "11.328217029571533\n",
            "torch.Size([6001, 30624])\n",
            "13.20327091217041\n",
            "torch.Size([7001, 30624])\n",
            "15.336836099624634\n",
            "torch.Size([8001, 30624])\n",
            "17.288937091827393\n",
            "torch.Size([9001, 30624])\n",
            "19.24294900894165\n",
            "torch.Size([10001, 30624])\n",
            "21.191832542419434\n",
            "torch.Size([11001, 30624])\n",
            "23.146239519119263\n",
            "torch.Size([12001, 30624])\n",
            "25.09600257873535\n",
            "torch.Size([13001, 30624])\n",
            "170.03065967559814\n",
            "torch.Size([14001, 30624])\n",
            "187.80506491661072\n",
            "torch.Size([15001, 30624])\n",
            "211.9542031288147\n",
            "torch.Size([16001, 30624])\n",
            "225.83997082710266\n",
            "torch.Size([17001, 30624])\n",
            "240.9227602481842\n",
            "torch.Size([17999, 30624])\n",
            "torch.Size([17999])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "br8deJ3RsNP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8041e13-102a-4ea3-8a39-6cc5b697823a"
      },
      "cell_type": "code",
      "source": [
        "features[0].shape"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30624])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "B2BNlqrAJleH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task1"
      ]
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xu-8rq-AJj0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3EY8WlEKQKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44ZSyECsKSpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 500)\n",
        "        self.lin2 = nn.Linear(500, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aboTbOIuyVd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1A = Model1A(VOCAB_SIZE)\n",
        "model1B = Model1B(VOCAB_SIZE)\n",
        "model1C = Model1C(VOCAB_SIZE)\n",
        "model1D = Model1D(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJgvIuflzD7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model1A.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eXZ5oiJz3oRs"
      },
      "cell_type": "markdown",
      "source": [
        "##Task2"
      ]
    },
    {
      "metadata": {
        "id": "AC5vnfLG3s8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 10)\n",
        "        self.lin2 = nn.Linear(10, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAl-p3ST3svP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 20)\n",
        "        self.lin2 = nn.Linear(20, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gI_C_AC3srz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 30)\n",
        "        self.lin3 = nn.Linear(30, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xeu29fbI3sjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWWVSG8z4rnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2E(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2E, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "y_MUqcWjpbBA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2A = Model2A(VOCAB_SIZE)\n",
        "model2B = Model2B(VOCAB_SIZE)\n",
        "model2C = Model2C(VOCAB_SIZE)\n",
        "model2D = Model2D(VOCAB_SIZE)\n",
        "model2E = Model2E(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gcyPaqzo42Ea"
      },
      "cell_type": "markdown",
      "source": [
        "##Task3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kire3o2W42Ed",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model3A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hPQL-96z42Eq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model3B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 100)\n",
        "        self.lin3 = nn.Linear(100, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6HYfG8pv2Wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3A = Model3A(VOCAB_SIZE)\n",
        "model3B = Model3B(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pGje3Qmb53SB"
      },
      "cell_type": "markdown",
      "source": [
        "##Task4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1q9dRGoH53SF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Cxk52Poe53SN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 100)\n",
        "        self.lin3 = nn.Linear(100,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7f8iUrh6K5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 10)\n",
        "        self.lin3 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UR_5Ny8Lc11s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model4A = Model4A(VOCAB_SIZE)\n",
        "model4B = Model4B(VOCAB_SIZE)\n",
        "model4C = Model4C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_P3kpbn6CkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task5"
      ]
    },
    {
      "metadata": {
        "id": "WyuNEDLy6F-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jvAMDPl6IDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.tanh(self.lin1(x))\n",
        "        x = F.tanh(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.tanh(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdBYZH5C6H-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.sigmoid(self.lin1(x))\n",
        "        x = F.sigmoid(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.sigmoid(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9q06ioWi6H4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model5A = Model5A(VOCAB_SIZE)\n",
        "model5B = Model5B(VOCAB_SIZE)\n",
        "model5C = Model5C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUigOUZZ6Hwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model5A.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XxKqNECsxCSU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task7"
      ]
    },
    {
      "metadata": {
        "id": "SzM0aA9fxIwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model7A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwlQU15XxP82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model7B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUzY81cYxSbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model7C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model7C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nV9Io_wkxYKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model7A = Model7A(VOCAB_SIZE)\n",
        "model7B = Model7B(VOCAB_SIZE)\n",
        "model7C = Model7C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMIoCKTv2oJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run code"
      ]
    },
    {
      "metadata": {
        "id": "I8yGFyUV-ykT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, isGpu):\n",
        "    if isGpu:\n",
        "        model = model.to(device)\n",
        "    # define a loss function and an optimizer\n",
        "    #loss_function = nn.NLLLoss()\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "    # the training loop\n",
        "    for epoch in range(30):\n",
        "        tic = time.time()\n",
        "        for batch_idx, (instance, label) in enumerate(train_loader):\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            label = label.long()\n",
        "            probs = model(instance) # forward pass\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovWIpc5K42Ff",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(model):\n",
        "    model = model.cpu()\n",
        "    preds = []\n",
        "    for instance, label in data_test:\n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "        logprobs = model(bow_vec)\n",
        "        #print(logprobs)\n",
        "        pred = np.argmax(logprobs.data.cpu().numpy())\n",
        "        preds.append(pred)\n",
        "\n",
        "    print('accuracy: {}'.format(accuracy_score(text_labels_test, preds)))\n",
        "    print('precision: {}'.format(precision_score(text_labels_test, preds)))\n",
        "    print('recall: {}'.format(recall_score(text_labels_test, preds)))\n",
        "    print('f1-score: {}'.format(f1_score(text_labels_test, preds)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "--MMxg1r42FR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_and_save(model): \n",
        "    train(model, True)\n",
        "    validate(model)\n",
        "    torch.save(model, model._get_name()+'.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9XtKcRrgwTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "a841c633-5f94-4c96-bf29-8480c5326876"
      },
      "cell_type": "code",
      "source": [
        "run_and_save(model1A)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.49253320693969727, TIME TAKEN: 0.8663370609283447\n",
            "EPOCH: 1, CURRENT LOSS: 0.4049370586872101, TIME TAKEN: 0.8625960350036621\n",
            "EPOCH: 2, CURRENT LOSS: 0.44335511326789856, TIME TAKEN: 0.8416721820831299\n",
            "EPOCH: 3, CURRENT LOSS: 0.4035332500934601, TIME TAKEN: 0.7402517795562744\n",
            "EPOCH: 4, CURRENT LOSS: 0.4415443539619446, TIME TAKEN: 0.7349205017089844\n",
            "EPOCH: 5, CURRENT LOSS: 0.41690030694007874, TIME TAKEN: 0.7394413948059082\n",
            "EPOCH: 6, CURRENT LOSS: 0.3134815990924835, TIME TAKEN: 0.7379934787750244\n",
            "EPOCH: 7, CURRENT LOSS: 0.40137526392936707, TIME TAKEN: 0.7404682636260986\n",
            "EPOCH: 8, CURRENT LOSS: 0.32842808961868286, TIME TAKEN: 0.8037106990814209\n",
            "EPOCH: 9, CURRENT LOSS: 0.40754494071006775, TIME TAKEN: 0.7976877689361572\n",
            "EPOCH: 10, CURRENT LOSS: 0.3270855247974396, TIME TAKEN: 0.796971321105957\n",
            "EPOCH: 11, CURRENT LOSS: 0.41997823119163513, TIME TAKEN: 0.7877819538116455\n",
            "EPOCH: 12, CURRENT LOSS: 0.3205462098121643, TIME TAKEN: 0.8043563365936279\n",
            "EPOCH: 13, CURRENT LOSS: 0.3146139681339264, TIME TAKEN: 0.8031837940216064\n",
            "EPOCH: 14, CURRENT LOSS: 0.38226011395454407, TIME TAKEN: 0.7823398113250732\n",
            "EPOCH: 15, CURRENT LOSS: 0.31341275572776794, TIME TAKEN: 0.7377867698669434\n",
            "EPOCH: 16, CURRENT LOSS: 0.31433504819869995, TIME TAKEN: 0.7280666828155518\n",
            "EPOCH: 17, CURRENT LOSS: 0.3808356821537018, TIME TAKEN: 0.737905740737915\n",
            "EPOCH: 18, CURRENT LOSS: 0.31550824642181396, TIME TAKEN: 0.7484700679779053\n",
            "EPOCH: 19, CURRENT LOSS: 0.3169088065624237, TIME TAKEN: 0.7247235774993896\n",
            "EPOCH: 20, CURRENT LOSS: 0.31390008330345154, TIME TAKEN: 0.7364556789398193\n",
            "EPOCH: 21, CURRENT LOSS: 0.3799673616886139, TIME TAKEN: 0.7332649230957031\n",
            "EPOCH: 22, CURRENT LOSS: 0.3857814371585846, TIME TAKEN: 0.739206075668335\n",
            "EPOCH: 23, CURRENT LOSS: 0.3157414495944977, TIME TAKEN: 0.7270948886871338\n",
            "EPOCH: 24, CURRENT LOSS: 0.3811413645744324, TIME TAKEN: 0.7357327938079834\n",
            "EPOCH: 25, CURRENT LOSS: 0.45646435022354126, TIME TAKEN: 0.7364938259124756\n",
            "EPOCH: 26, CURRENT LOSS: 0.31396713852882385, TIME TAKEN: 0.7201228141784668\n",
            "EPOCH: 27, CURRENT LOSS: 0.3150005340576172, TIME TAKEN: 0.7355442047119141\n",
            "EPOCH: 28, CURRENT LOSS: 0.31338921189308167, TIME TAKEN: 0.7390434741973877\n",
            "EPOCH: 29, CURRENT LOSS: 0.31435590982437134, TIME TAKEN: 0.7312321662902832\n",
            "accuracy: 0.8774\n",
            "precision: 0.8829915560916767\n",
            "recall: 0.8721207307386815\n",
            "f1-score: 0.8775224775224775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model1A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "acUKLyI3gvpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11869
        },
        "outputId": "d33ced37-4385-48f5-8e2d-b02f55b3ad6c"
      },
      "cell_type": "code",
      "source": [
        "run_and_save(model1B)\n",
        "run_and_save(model1C)\n",
        "run_and_save(model1D)\n",
        "run_and_save(model2A)\n",
        "run_and_save(model2B)\n",
        "run_and_save(model2C)\n",
        "run_and_save(model2D)\n",
        "run_and_save(model2E)\n",
        "run_and_save(model3A)\n",
        "run_and_save(model3B)\n",
        "run_and_save(model4A)\n",
        "run_and_save(model4B)\n",
        "run_and_save(model4C)\n",
        "run_and_save(model5A)\n",
        "run_and_save(model5B)\n",
        "run_and_save(model5C)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4651903212070465, TIME TAKEN: 0.9849138259887695\n",
            "EPOCH: 1, CURRENT LOSS: 0.43574467301368713, TIME TAKEN: 0.8667426109313965\n",
            "EPOCH: 2, CURRENT LOSS: 0.3871213495731354, TIME TAKEN: 0.8575284481048584\n",
            "EPOCH: 3, CURRENT LOSS: 0.36921584606170654, TIME TAKEN: 0.8541278839111328\n",
            "EPOCH: 4, CURRENT LOSS: 0.3813888430595398, TIME TAKEN: 0.8550138473510742\n",
            "EPOCH: 5, CURRENT LOSS: 0.31594160199165344, TIME TAKEN: 0.8549597263336182\n",
            "EPOCH: 6, CURRENT LOSS: 0.3977689743041992, TIME TAKEN: 0.8568789958953857\n",
            "EPOCH: 7, CURRENT LOSS: 0.31725195050239563, TIME TAKEN: 0.851722240447998\n",
            "EPOCH: 8, CURRENT LOSS: 0.3200514018535614, TIME TAKEN: 0.8576686382293701\n",
            "EPOCH: 9, CURRENT LOSS: 0.3155335783958435, TIME TAKEN: 0.856403112411499\n",
            "EPOCH: 10, CURRENT LOSS: 0.42370137572288513, TIME TAKEN: 0.8577849864959717\n",
            "EPOCH: 11, CURRENT LOSS: 0.38885733485221863, TIME TAKEN: 0.8560278415679932\n",
            "EPOCH: 12, CURRENT LOSS: 0.36514949798583984, TIME TAKEN: 0.8566176891326904\n",
            "EPOCH: 13, CURRENT LOSS: 0.38182398676872253, TIME TAKEN: 0.8546633720397949\n",
            "EPOCH: 14, CURRENT LOSS: 0.36534202098846436, TIME TAKEN: 0.8562877178192139\n",
            "EPOCH: 15, CURRENT LOSS: 0.3147736191749573, TIME TAKEN: 0.8561277389526367\n",
            "EPOCH: 16, CURRENT LOSS: 0.3436949551105499, TIME TAKEN: 0.855827808380127\n",
            "EPOCH: 17, CURRENT LOSS: 0.38593050837516785, TIME TAKEN: 0.8551626205444336\n",
            "EPOCH: 18, CURRENT LOSS: 0.31335899233818054, TIME TAKEN: 0.8554263114929199\n",
            "EPOCH: 19, CURRENT LOSS: 0.31491386890411377, TIME TAKEN: 0.8557219505310059\n",
            "EPOCH: 20, CURRENT LOSS: 0.31734880805015564, TIME TAKEN: 0.8534348011016846\n",
            "EPOCH: 21, CURRENT LOSS: 0.31804123520851135, TIME TAKEN: 0.8506646156311035\n",
            "EPOCH: 22, CURRENT LOSS: 0.3135944902896881, TIME TAKEN: 0.8512787818908691\n",
            "EPOCH: 23, CURRENT LOSS: 0.31338632106781006, TIME TAKEN: 0.8526425361633301\n",
            "EPOCH: 24, CURRENT LOSS: 0.31644874811172485, TIME TAKEN: 0.8507802486419678\n",
            "EPOCH: 25, CURRENT LOSS: 0.3138314485549927, TIME TAKEN: 0.8550229072570801\n",
            "EPOCH: 26, CURRENT LOSS: 0.44623851776123047, TIME TAKEN: 0.8556880950927734\n",
            "EPOCH: 27, CURRENT LOSS: 0.3139290511608124, TIME TAKEN: 0.8557758331298828\n",
            "EPOCH: 28, CURRENT LOSS: 0.3803001940250397, TIME TAKEN: 0.8557858467102051\n",
            "EPOCH: 29, CURRENT LOSS: 0.3144625127315521, TIME TAKEN: 0.85540771484375\n",
            "accuracy: 0.8742\n",
            "precision: 0.8740594059405941\n",
            "recall: 0.8764892772041303\n",
            "f1-score: 0.875272655165576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model1B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.43329036235809326, TIME TAKEN: 1.5475678443908691\n",
            "EPOCH: 1, CURRENT LOSS: 0.36012929677963257, TIME TAKEN: 1.4276082515716553\n",
            "EPOCH: 2, CURRENT LOSS: 0.38632506132125854, TIME TAKEN: 1.43056321144104\n",
            "EPOCH: 3, CURRENT LOSS: 0.32468318939208984, TIME TAKEN: 1.428098201751709\n",
            "EPOCH: 4, CURRENT LOSS: 0.44756805896759033, TIME TAKEN: 1.4268500804901123\n",
            "EPOCH: 5, CURRENT LOSS: 0.44814857840538025, TIME TAKEN: 1.4288887977600098\n",
            "EPOCH: 6, CURRENT LOSS: 0.3242698013782501, TIME TAKEN: 1.4301447868347168\n",
            "EPOCH: 7, CURRENT LOSS: 0.4683738052845001, TIME TAKEN: 1.429511547088623\n",
            "EPOCH: 8, CURRENT LOSS: 0.37214699387550354, TIME TAKEN: 1.4311931133270264\n",
            "EPOCH: 9, CURRENT LOSS: 0.3845963180065155, TIME TAKEN: 1.4268698692321777\n",
            "EPOCH: 10, CURRENT LOSS: 0.37175002694129944, TIME TAKEN: 1.4248929023742676\n",
            "EPOCH: 11, CURRENT LOSS: 0.313803493976593, TIME TAKEN: 1.422123670578003\n",
            "EPOCH: 12, CURRENT LOSS: 0.39632999897003174, TIME TAKEN: 1.4298532009124756\n",
            "EPOCH: 13, CURRENT LOSS: 0.31398138403892517, TIME TAKEN: 1.4281578063964844\n",
            "EPOCH: 14, CURRENT LOSS: 0.332407683134079, TIME TAKEN: 1.4290311336517334\n",
            "EPOCH: 15, CURRENT LOSS: 0.32102105021476746, TIME TAKEN: 1.4280390739440918\n",
            "EPOCH: 16, CURRENT LOSS: 0.3160349428653717, TIME TAKEN: 1.4290969371795654\n",
            "EPOCH: 17, CURRENT LOSS: 0.4505005180835724, TIME TAKEN: 1.4294421672821045\n",
            "EPOCH: 18, CURRENT LOSS: 0.3158699572086334, TIME TAKEN: 1.427722454071045\n",
            "EPOCH: 19, CURRENT LOSS: 0.31584885716438293, TIME TAKEN: 1.4296393394470215\n",
            "EPOCH: 20, CURRENT LOSS: 0.31419068574905396, TIME TAKEN: 1.4286777973175049\n",
            "EPOCH: 21, CURRENT LOSS: 0.3807591497898102, TIME TAKEN: 1.4297871589660645\n",
            "EPOCH: 22, CURRENT LOSS: 0.3140050768852234, TIME TAKEN: 1.4297945499420166\n",
            "EPOCH: 23, CURRENT LOSS: 0.31432291865348816, TIME TAKEN: 1.4303088188171387\n",
            "EPOCH: 24, CURRENT LOSS: 0.3147997558116913, TIME TAKEN: 1.430429220199585\n",
            "EPOCH: 25, CURRENT LOSS: 0.38005897402763367, TIME TAKEN: 1.4275438785552979\n",
            "EPOCH: 26, CURRENT LOSS: 0.3134266436100006, TIME TAKEN: 1.4303865432739258\n",
            "EPOCH: 27, CURRENT LOSS: 0.31332966685295105, TIME TAKEN: 1.4291088581085205\n",
            "EPOCH: 28, CURRENT LOSS: 0.31627312302589417, TIME TAKEN: 1.4295241832733154\n",
            "EPOCH: 29, CURRENT LOSS: 0.3142080307006836, TIME TAKEN: 1.4316949844360352\n",
            "accuracy: 0.8764\n",
            "precision: 0.8861788617886179\n",
            "recall: 0.8657664813343924\n",
            "f1-score: 0.8758537565287264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model1C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4478102922439575, TIME TAKEN: 2.938095808029175\n",
            "EPOCH: 1, CURRENT LOSS: 0.3458084166049957, TIME TAKEN: 2.8341448307037354\n",
            "EPOCH: 2, CURRENT LOSS: 0.44719812273979187, TIME TAKEN: 2.8341686725616455\n",
            "EPOCH: 3, CURRENT LOSS: 0.5156257748603821, TIME TAKEN: 2.835313558578491\n",
            "EPOCH: 4, CURRENT LOSS: 0.3266957402229309, TIME TAKEN: 2.8371148109436035\n",
            "EPOCH: 5, CURRENT LOSS: 0.3343895375728607, TIME TAKEN: 2.8357129096984863\n",
            "EPOCH: 6, CURRENT LOSS: 0.41682034730911255, TIME TAKEN: 2.8337759971618652\n",
            "EPOCH: 7, CURRENT LOSS: 0.3240929841995239, TIME TAKEN: 2.834514617919922\n",
            "EPOCH: 8, CURRENT LOSS: 0.31863725185394287, TIME TAKEN: 2.8230056762695312\n",
            "EPOCH: 9, CURRENT LOSS: 0.3133929669857025, TIME TAKEN: 2.8285746574401855\n",
            "EPOCH: 10, CURRENT LOSS: 0.5037187933921814, TIME TAKEN: 2.814847469329834\n",
            "EPOCH: 11, CURRENT LOSS: 0.4055578112602234, TIME TAKEN: 2.80869460105896\n",
            "EPOCH: 12, CURRENT LOSS: 0.390415757894516, TIME TAKEN: 2.8092808723449707\n",
            "EPOCH: 13, CURRENT LOSS: 0.3367040753364563, TIME TAKEN: 2.815138101577759\n",
            "EPOCH: 14, CURRENT LOSS: 0.38374999165534973, TIME TAKEN: 2.834789276123047\n",
            "EPOCH: 15, CURRENT LOSS: 0.3823884129524231, TIME TAKEN: 2.8362886905670166\n",
            "EPOCH: 16, CURRENT LOSS: 0.34238776564598083, TIME TAKEN: 2.8291473388671875\n",
            "EPOCH: 17, CURRENT LOSS: 0.3154134154319763, TIME TAKEN: 2.834784984588623\n",
            "EPOCH: 18, CURRENT LOSS: 0.3788725733757019, TIME TAKEN: 2.834484577178955\n",
            "EPOCH: 19, CURRENT LOSS: 0.44789355993270874, TIME TAKEN: 2.8346245288848877\n",
            "EPOCH: 20, CURRENT LOSS: 0.31698787212371826, TIME TAKEN: 2.8347272872924805\n",
            "EPOCH: 21, CURRENT LOSS: 0.3135404586791992, TIME TAKEN: 2.8351640701293945\n",
            "EPOCH: 22, CURRENT LOSS: 0.3805030286312103, TIME TAKEN: 2.836510419845581\n",
            "EPOCH: 23, CURRENT LOSS: 0.3134920001029968, TIME TAKEN: 2.8372042179107666\n",
            "EPOCH: 24, CURRENT LOSS: 0.31415387988090515, TIME TAKEN: 2.8338851928710938\n",
            "EPOCH: 25, CURRENT LOSS: 0.3161940574645996, TIME TAKEN: 2.8338372707366943\n",
            "EPOCH: 26, CURRENT LOSS: 0.31475263833999634, TIME TAKEN: 2.835503101348877\n",
            "EPOCH: 27, CURRENT LOSS: 0.3805195391178131, TIME TAKEN: 2.836148738861084\n",
            "EPOCH: 28, CURRENT LOSS: 0.3802289068698883, TIME TAKEN: 2.827615261077881\n",
            "EPOCH: 29, CURRENT LOSS: 0.38211050629615784, TIME TAKEN: 2.8349413871765137\n",
            "accuracy: 0.8754\n",
            "precision: 0.8720062819002748\n",
            "recall: 0.8820492454328832\n",
            "f1-score: 0.8769990128331687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model1D. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5270233750343323, TIME TAKEN: 0.836301326751709\n",
            "EPOCH: 1, CURRENT LOSS: 0.447546124458313, TIME TAKEN: 0.8313806056976318\n",
            "EPOCH: 2, CURRENT LOSS: 0.42085501551628113, TIME TAKEN: 0.8397316932678223\n",
            "EPOCH: 3, CURRENT LOSS: 0.4916667342185974, TIME TAKEN: 0.8312079906463623\n",
            "EPOCH: 4, CURRENT LOSS: 0.49554646015167236, TIME TAKEN: 0.8350443840026855\n",
            "EPOCH: 5, CURRENT LOSS: 0.512822687625885, TIME TAKEN: 0.82314133644104\n",
            "EPOCH: 6, CURRENT LOSS: 0.3235947787761688, TIME TAKEN: 0.8399455547332764\n",
            "EPOCH: 7, CURRENT LOSS: 0.3853662312030792, TIME TAKEN: 0.8424296379089355\n",
            "EPOCH: 8, CURRENT LOSS: 0.4484509527683258, TIME TAKEN: 0.8417747020721436\n",
            "EPOCH: 9, CURRENT LOSS: 0.31530991196632385, TIME TAKEN: 0.8427727222442627\n",
            "EPOCH: 10, CURRENT LOSS: 0.31521767377853394, TIME TAKEN: 0.8397848606109619\n",
            "EPOCH: 11, CURRENT LOSS: 0.3869982063770294, TIME TAKEN: 0.8224802017211914\n",
            "EPOCH: 12, CURRENT LOSS: 0.31351831555366516, TIME TAKEN: 0.8382515907287598\n",
            "EPOCH: 13, CURRENT LOSS: 0.3142677843570709, TIME TAKEN: 0.8692479133605957\n",
            "EPOCH: 14, CURRENT LOSS: 0.38707658648490906, TIME TAKEN: 0.8510305881500244\n",
            "EPOCH: 15, CURRENT LOSS: 0.4209226965904236, TIME TAKEN: 0.8522646427154541\n",
            "EPOCH: 16, CURRENT LOSS: 0.38046714663505554, TIME TAKEN: 0.8499388694763184\n",
            "EPOCH: 17, CURRENT LOSS: 0.3137439489364624, TIME TAKEN: 0.8362150192260742\n",
            "EPOCH: 18, CURRENT LOSS: 0.4465954899787903, TIME TAKEN: 0.8413751125335693\n",
            "EPOCH: 19, CURRENT LOSS: 0.3132621943950653, TIME TAKEN: 0.8369803428649902\n",
            "EPOCH: 20, CURRENT LOSS: 0.31326159834861755, TIME TAKEN: 0.8423373699188232\n",
            "EPOCH: 21, CURRENT LOSS: 0.38008633255958557, TIME TAKEN: 0.8318521976470947\n",
            "EPOCH: 22, CURRENT LOSS: 0.31327468156814575, TIME TAKEN: 0.8230531215667725\n",
            "EPOCH: 23, CURRENT LOSS: 0.31326332688331604, TIME TAKEN: 0.8383522033691406\n",
            "EPOCH: 24, CURRENT LOSS: 0.38009679317474365, TIME TAKEN: 0.8482134342193604\n",
            "EPOCH: 25, CURRENT LOSS: 0.3843119442462921, TIME TAKEN: 0.851121187210083\n",
            "EPOCH: 26, CURRENT LOSS: 0.3134738504886627, TIME TAKEN: 0.8363895416259766\n",
            "EPOCH: 27, CURRENT LOSS: 0.313390851020813, TIME TAKEN: 0.827202320098877\n",
            "EPOCH: 28, CURRENT LOSS: 0.37993231415748596, TIME TAKEN: 0.8336689472198486\n",
            "EPOCH: 29, CURRENT LOSS: 0.5799282789230347, TIME TAKEN: 0.8385810852050781\n",
            "accuracy: 0.789\n",
            "precision: 0.9377618192698982\n",
            "recall: 0.6223193010325655\n",
            "f1-score: 0.7481499164478395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model2A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4256751239299774, TIME TAKEN: 0.8427698612213135\n",
            "EPOCH: 1, CURRENT LOSS: 0.32890209555625916, TIME TAKEN: 0.8326942920684814\n",
            "EPOCH: 2, CURRENT LOSS: 0.7623302936553955, TIME TAKEN: 0.8302943706512451\n",
            "EPOCH: 3, CURRENT LOSS: 0.5043177604675293, TIME TAKEN: 0.8503892421722412\n",
            "EPOCH: 4, CURRENT LOSS: 0.318499356508255, TIME TAKEN: 0.829552412033081\n",
            "EPOCH: 5, CURRENT LOSS: 0.4321397840976715, TIME TAKEN: 0.8404126167297363\n",
            "EPOCH: 6, CURRENT LOSS: 0.31886351108551025, TIME TAKEN: 0.8393914699554443\n",
            "EPOCH: 7, CURRENT LOSS: 0.3957653045654297, TIME TAKEN: 0.822833776473999\n",
            "EPOCH: 8, CURRENT LOSS: 0.38066670298576355, TIME TAKEN: 0.8322885036468506\n",
            "EPOCH: 9, CURRENT LOSS: 0.43317607045173645, TIME TAKEN: 0.8366413116455078\n",
            "EPOCH: 10, CURRENT LOSS: 0.3800358474254608, TIME TAKEN: 0.8429782390594482\n",
            "EPOCH: 11, CURRENT LOSS: 0.38065555691719055, TIME TAKEN: 0.8322679996490479\n",
            "EPOCH: 12, CURRENT LOSS: 0.32404473423957825, TIME TAKEN: 0.8388993740081787\n",
            "EPOCH: 13, CURRENT LOSS: 0.37997275590896606, TIME TAKEN: 0.8268988132476807\n",
            "EPOCH: 14, CURRENT LOSS: 0.3290908634662628, TIME TAKEN: 0.832866907119751\n",
            "EPOCH: 15, CURRENT LOSS: 0.4467129707336426, TIME TAKEN: 0.8311030864715576\n",
            "EPOCH: 16, CURRENT LOSS: 0.31328922510147095, TIME TAKEN: 0.8365647792816162\n",
            "EPOCH: 17, CURRENT LOSS: 0.3138130009174347, TIME TAKEN: 0.834414005279541\n",
            "EPOCH: 18, CURRENT LOSS: 0.3509630858898163, TIME TAKEN: 0.8232309818267822\n",
            "EPOCH: 19, CURRENT LOSS: 0.35503023862838745, TIME TAKEN: 0.8317966461181641\n",
            "EPOCH: 20, CURRENT LOSS: 0.3134680986404419, TIME TAKEN: 0.8407211303710938\n",
            "EPOCH: 21, CURRENT LOSS: 0.3145518898963928, TIME TAKEN: 0.8263943195343018\n",
            "EPOCH: 22, CURRENT LOSS: 0.3800511658191681, TIME TAKEN: 0.8319787979125977\n",
            "EPOCH: 23, CURRENT LOSS: 0.3743722140789032, TIME TAKEN: 0.8211138248443604\n",
            "EPOCH: 24, CURRENT LOSS: 0.31342610716819763, TIME TAKEN: 0.8262767791748047\n",
            "EPOCH: 25, CURRENT LOSS: 0.313262403011322, TIME TAKEN: 0.8270881175994873\n",
            "EPOCH: 26, CURRENT LOSS: 0.4470345377922058, TIME TAKEN: 0.8285446166992188\n",
            "EPOCH: 27, CURRENT LOSS: 0.34583932161331177, TIME TAKEN: 0.8291654586791992\n",
            "EPOCH: 28, CURRENT LOSS: 0.3136211037635803, TIME TAKEN: 0.821974515914917\n",
            "EPOCH: 29, CURRENT LOSS: 0.37992897629737854, TIME TAKEN: 0.8319613933563232\n",
            "accuracy: 0.8716\n",
            "precision: 0.8764044943820225\n",
            "recall: 0.8673550436854647\n",
            "f1-score: 0.8718562874251496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model2B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.7378908395767212, TIME TAKEN: 0.8447999954223633\n",
            "EPOCH: 1, CURRENT LOSS: 0.47293728590011597, TIME TAKEN: 0.8519418239593506\n",
            "EPOCH: 2, CURRENT LOSS: 0.39725854992866516, TIME TAKEN: 0.847285270690918\n",
            "EPOCH: 3, CURRENT LOSS: 0.5117624402046204, TIME TAKEN: 0.8606464862823486\n",
            "EPOCH: 4, CURRENT LOSS: 0.31398874521255493, TIME TAKEN: 0.8536839485168457\n",
            "EPOCH: 5, CURRENT LOSS: 0.3223706781864166, TIME TAKEN: 0.8428750038146973\n",
            "EPOCH: 6, CURRENT LOSS: 0.5398231744766235, TIME TAKEN: 0.8452353477478027\n",
            "EPOCH: 7, CURRENT LOSS: 0.3187846541404724, TIME TAKEN: 0.8416473865509033\n",
            "EPOCH: 8, CURRENT LOSS: 0.31330862641334534, TIME TAKEN: 0.8366951942443848\n",
            "EPOCH: 9, CURRENT LOSS: 0.41147321462631226, TIME TAKEN: 0.8452060222625732\n",
            "EPOCH: 10, CURRENT LOSS: 0.3810039758682251, TIME TAKEN: 0.8485298156738281\n",
            "EPOCH: 11, CURRENT LOSS: 0.3384169936180115, TIME TAKEN: 0.8364076614379883\n",
            "EPOCH: 12, CURRENT LOSS: 0.3808888792991638, TIME TAKEN: 0.8374826908111572\n",
            "EPOCH: 13, CURRENT LOSS: 0.38005557656288147, TIME TAKEN: 0.8382458686828613\n",
            "EPOCH: 14, CURRENT LOSS: 0.3189195990562439, TIME TAKEN: 0.8295102119445801\n",
            "EPOCH: 15, CURRENT LOSS: 0.3139533996582031, TIME TAKEN: 0.8369178771972656\n",
            "EPOCH: 16, CURRENT LOSS: 0.3238263726234436, TIME TAKEN: 0.842339038848877\n",
            "EPOCH: 17, CURRENT LOSS: 0.3185234069824219, TIME TAKEN: 0.8362023830413818\n",
            "EPOCH: 18, CURRENT LOSS: 0.31477585434913635, TIME TAKEN: 0.8368253707885742\n",
            "EPOCH: 19, CURRENT LOSS: 0.31463831663131714, TIME TAKEN: 0.8212409019470215\n",
            "EPOCH: 20, CURRENT LOSS: 0.31514614820480347, TIME TAKEN: 0.8372170925140381\n",
            "EPOCH: 21, CURRENT LOSS: 0.43689364194869995, TIME TAKEN: 0.838367223739624\n",
            "EPOCH: 22, CURRENT LOSS: 0.3132714033126831, TIME TAKEN: 0.8385865688323975\n",
            "EPOCH: 23, CURRENT LOSS: 0.3144735097885132, TIME TAKEN: 0.8357391357421875\n",
            "EPOCH: 24, CURRENT LOSS: 0.3137083351612091, TIME TAKEN: 0.8296256065368652\n",
            "EPOCH: 25, CURRENT LOSS: 0.31326183676719666, TIME TAKEN: 0.8336086273193359\n",
            "EPOCH: 26, CURRENT LOSS: 0.31387627124786377, TIME TAKEN: 0.8383035659790039\n",
            "EPOCH: 27, CURRENT LOSS: 0.31414663791656494, TIME TAKEN: 0.8352108001708984\n",
            "EPOCH: 28, CURRENT LOSS: 0.3799282908439636, TIME TAKEN: 0.8365099430084229\n",
            "EPOCH: 29, CURRENT LOSS: 0.4465954601764679, TIME TAKEN: 0.8339910507202148\n",
            "accuracy: 0.8124\n",
            "precision: 0.7439777640518839\n",
            "recall: 0.9567116759332804\n",
            "f1-score: 0.8370396108408618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model2C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.46580225229263306, TIME TAKEN: 0.8395206928253174\n",
            "EPOCH: 1, CURRENT LOSS: 0.6157767176628113, TIME TAKEN: 0.8373820781707764\n",
            "EPOCH: 2, CURRENT LOSS: 0.3870270848274231, TIME TAKEN: 0.8310379981994629\n",
            "EPOCH: 3, CURRENT LOSS: 0.5691075921058655, TIME TAKEN: 0.8378093242645264\n",
            "EPOCH: 4, CURRENT LOSS: 0.37791818380355835, TIME TAKEN: 0.8338351249694824\n",
            "EPOCH: 5, CURRENT LOSS: 0.42524492740631104, TIME TAKEN: 0.8470308780670166\n",
            "EPOCH: 6, CURRENT LOSS: 0.38104644417762756, TIME TAKEN: 0.8338792324066162\n",
            "EPOCH: 7, CURRENT LOSS: 0.37716954946517944, TIME TAKEN: 0.8427495956420898\n",
            "EPOCH: 8, CURRENT LOSS: 0.3268861472606659, TIME TAKEN: 0.845940351486206\n",
            "EPOCH: 9, CURRENT LOSS: 0.31643199920654297, TIME TAKEN: 0.8348681926727295\n",
            "EPOCH: 10, CURRENT LOSS: 0.3138923645019531, TIME TAKEN: 0.8378188610076904\n",
            "EPOCH: 11, CURRENT LOSS: 0.508809506893158, TIME TAKEN: 0.8331089019775391\n",
            "EPOCH: 12, CURRENT LOSS: 0.3132741153240204, TIME TAKEN: 0.8405711650848389\n",
            "EPOCH: 13, CURRENT LOSS: 0.31326165795326233, TIME TAKEN: 0.8457179069519043\n",
            "EPOCH: 14, CURRENT LOSS: 0.31501901149749756, TIME TAKEN: 0.8361232280731201\n",
            "EPOCH: 15, CURRENT LOSS: 0.313444584608078, TIME TAKEN: 0.838301420211792\n",
            "EPOCH: 16, CURRENT LOSS: 0.31537848711013794, TIME TAKEN: 0.8324401378631592\n",
            "EPOCH: 17, CURRENT LOSS: 0.42018556594848633, TIME TAKEN: 0.8240706920623779\n",
            "EPOCH: 18, CURRENT LOSS: 0.3138715624809265, TIME TAKEN: 0.8298165798187256\n",
            "EPOCH: 19, CURRENT LOSS: 0.3136391341686249, TIME TAKEN: 0.8303606510162354\n",
            "EPOCH: 20, CURRENT LOSS: 0.3809416592121124, TIME TAKEN: 0.834082841873169\n",
            "EPOCH: 21, CURRENT LOSS: 0.32047876715660095, TIME TAKEN: 0.8332314491271973\n",
            "EPOCH: 22, CURRENT LOSS: 0.3134690523147583, TIME TAKEN: 0.8179500102996826\n",
            "EPOCH: 23, CURRENT LOSS: 0.3745670020580292, TIME TAKEN: 0.8318371772766113\n",
            "EPOCH: 24, CURRENT LOSS: 0.3135802447795868, TIME TAKEN: 0.8314580917358398\n",
            "EPOCH: 25, CURRENT LOSS: 0.3799283802509308, TIME TAKEN: 0.8303356170654297\n",
            "EPOCH: 26, CURRENT LOSS: 0.3146490156650543, TIME TAKEN: 0.8320169448852539\n",
            "EPOCH: 27, CURRENT LOSS: 0.31420624256134033, TIME TAKEN: 0.8255517482757568\n",
            "EPOCH: 28, CURRENT LOSS: 0.31327909231185913, TIME TAKEN: 0.826014518737793\n",
            "EPOCH: 29, CURRENT LOSS: 0.31338921189308167, TIME TAKEN: 0.8325345516204834\n",
            "accuracy: 0.8696\n",
            "precision: 0.8658823529411764\n",
            "recall: 0.8768864177918984\n",
            "f1-score: 0.8713496448303077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model2D. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4413723647594452, TIME TAKEN: 0.9342522621154785\n",
            "EPOCH: 1, CURRENT LOSS: 0.47891291975975037, TIME TAKEN: 0.9333350658416748\n",
            "EPOCH: 2, CURRENT LOSS: 0.39187803864479065, TIME TAKEN: 0.9395365715026855\n",
            "EPOCH: 3, CURRENT LOSS: 0.45353829860687256, TIME TAKEN: 0.9322149753570557\n",
            "EPOCH: 4, CURRENT LOSS: 0.31326812505722046, TIME TAKEN: 0.9319627285003662\n",
            "EPOCH: 5, CURRENT LOSS: 0.38479116559028625, TIME TAKEN: 0.929492712020874\n",
            "EPOCH: 6, CURRENT LOSS: 0.31719332933425903, TIME TAKEN: 0.9343929290771484\n",
            "EPOCH: 7, CURRENT LOSS: 0.4095441401004791, TIME TAKEN: 0.935713529586792\n",
            "EPOCH: 8, CURRENT LOSS: 0.44623714685440063, TIME TAKEN: 0.9340250492095947\n",
            "EPOCH: 9, CURRENT LOSS: 0.31326422095298767, TIME TAKEN: 0.9354028701782227\n",
            "EPOCH: 10, CURRENT LOSS: 0.38040509819984436, TIME TAKEN: 0.9357624053955078\n",
            "EPOCH: 11, CURRENT LOSS: 0.44035962224006653, TIME TAKEN: 0.9359097480773926\n",
            "EPOCH: 12, CURRENT LOSS: 0.3134903907775879, TIME TAKEN: 0.935570240020752\n",
            "EPOCH: 13, CURRENT LOSS: 0.3151892423629761, TIME TAKEN: 0.9390449523925781\n",
            "EPOCH: 14, CURRENT LOSS: 0.31326282024383545, TIME TAKEN: 0.9368102550506592\n",
            "EPOCH: 15, CURRENT LOSS: 0.3799225986003876, TIME TAKEN: 0.9348642826080322\n",
            "EPOCH: 16, CURRENT LOSS: 0.4465952515602112, TIME TAKEN: 0.9370326995849609\n",
            "EPOCH: 17, CURRENT LOSS: 0.37993237376213074, TIME TAKEN: 0.9379458427429199\n",
            "EPOCH: 18, CURRENT LOSS: 0.446871817111969, TIME TAKEN: 0.9364273548126221\n",
            "EPOCH: 19, CURRENT LOSS: 0.3133212924003601, TIME TAKEN: 0.9387032985687256\n",
            "EPOCH: 20, CURRENT LOSS: 0.31332799792289734, TIME TAKEN: 0.9420607089996338\n",
            "EPOCH: 21, CURRENT LOSS: 0.38508567214012146, TIME TAKEN: 0.9393575191497803\n",
            "EPOCH: 22, CURRENT LOSS: 0.3739929795265198, TIME TAKEN: 0.9411075115203857\n",
            "EPOCH: 23, CURRENT LOSS: 0.3133629560470581, TIME TAKEN: 0.9454402923583984\n",
            "EPOCH: 24, CURRENT LOSS: 0.38088035583496094, TIME TAKEN: 0.9405372142791748\n",
            "EPOCH: 25, CURRENT LOSS: 0.31326159834861755, TIME TAKEN: 0.9392051696777344\n",
            "EPOCH: 26, CURRENT LOSS: 0.3132964074611664, TIME TAKEN: 0.9377362728118896\n",
            "EPOCH: 27, CURRENT LOSS: 0.49893638491630554, TIME TAKEN: 0.9379334449768066\n",
            "EPOCH: 28, CURRENT LOSS: 0.31343168020248413, TIME TAKEN: 0.9377741813659668\n",
            "EPOCH: 29, CURRENT LOSS: 0.33851659297943115, TIME TAKEN: 0.9381165504455566\n",
            "accuracy: 0.869\n",
            "precision: 0.8935361216730038\n",
            "recall: 0.8399523431294679\n",
            "f1-score: 0.8659160696008189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model2E. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5184323787689209, TIME TAKEN: 1.1261465549468994\n",
            "EPOCH: 1, CURRENT LOSS: 0.39320436120033264, TIME TAKEN: 1.002861499786377\n",
            "EPOCH: 2, CURRENT LOSS: 0.5771729946136475, TIME TAKEN: 1.001817226409912\n",
            "EPOCH: 3, CURRENT LOSS: 0.386016309261322, TIME TAKEN: 0.9969131946563721\n",
            "EPOCH: 4, CURRENT LOSS: 0.5138975381851196, TIME TAKEN: 0.9996850490570068\n",
            "EPOCH: 5, CURRENT LOSS: 0.36161932349205017, TIME TAKEN: 0.9996047019958496\n",
            "EPOCH: 6, CURRENT LOSS: 0.3998560607433319, TIME TAKEN: 0.9987685680389404\n",
            "EPOCH: 7, CURRENT LOSS: 0.38076117634773254, TIME TAKEN: 0.9967546463012695\n",
            "EPOCH: 8, CURRENT LOSS: 0.3811712861061096, TIME TAKEN: 1.0028111934661865\n",
            "EPOCH: 9, CURRENT LOSS: 0.31345266103744507, TIME TAKEN: 1.0013227462768555\n",
            "EPOCH: 10, CURRENT LOSS: 0.3799513280391693, TIME TAKEN: 0.999086856842041\n",
            "EPOCH: 11, CURRENT LOSS: 0.3134165406227112, TIME TAKEN: 1.0024664402008057\n",
            "EPOCH: 12, CURRENT LOSS: 0.4467795193195343, TIME TAKEN: 1.0011208057403564\n",
            "EPOCH: 13, CURRENT LOSS: 0.31395038962364197, TIME TAKEN: 0.998481035232544\n",
            "EPOCH: 14, CURRENT LOSS: 0.37997856736183167, TIME TAKEN: 1.0050230026245117\n",
            "EPOCH: 15, CURRENT LOSS: 0.5016617178916931, TIME TAKEN: 0.9897239208221436\n",
            "EPOCH: 16, CURRENT LOSS: 0.31336066126823425, TIME TAKEN: 0.9972279071807861\n",
            "EPOCH: 17, CURRENT LOSS: 0.3801007866859436, TIME TAKEN: 0.9987542629241943\n",
            "EPOCH: 18, CURRENT LOSS: 0.31326156854629517, TIME TAKEN: 0.9981129169464111\n",
            "EPOCH: 19, CURRENT LOSS: 0.3203889727592468, TIME TAKEN: 1.0005924701690674\n",
            "EPOCH: 20, CURRENT LOSS: 0.3799286484718323, TIME TAKEN: 0.9994370937347412\n",
            "EPOCH: 21, CURRENT LOSS: 0.31335777044296265, TIME TAKEN: 0.9987547397613525\n",
            "EPOCH: 22, CURRENT LOSS: 0.44282010197639465, TIME TAKEN: 1.0011589527130127\n",
            "EPOCH: 23, CURRENT LOSS: 0.31326770782470703, TIME TAKEN: 1.0008773803710938\n",
            "EPOCH: 24, CURRENT LOSS: 0.3132626414299011, TIME TAKEN: 0.9993679523468018\n",
            "EPOCH: 25, CURRENT LOSS: 0.31326156854629517, TIME TAKEN: 1.0004305839538574\n",
            "EPOCH: 26, CURRENT LOSS: 0.31534168124198914, TIME TAKEN: 1.000467300415039\n",
            "EPOCH: 27, CURRENT LOSS: 0.31399428844451904, TIME TAKEN: 0.9987061023712158\n",
            "EPOCH: 28, CURRENT LOSS: 0.3133240044116974, TIME TAKEN: 0.999610424041748\n",
            "EPOCH: 29, CURRENT LOSS: 0.40942007303237915, TIME TAKEN: 1.0022976398468018\n",
            "accuracy: 0.814\n",
            "precision: 0.9470720720720721\n",
            "recall: 0.6679904686258936\n",
            "f1-score: 0.7834187238006521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model3A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.46301552653312683, TIME TAKEN: 1.7537906169891357\n",
            "EPOCH: 1, CURRENT LOSS: 0.5503860116004944, TIME TAKEN: 1.6486234664916992\n",
            "EPOCH: 2, CURRENT LOSS: 0.31376296281814575, TIME TAKEN: 1.6482508182525635\n",
            "EPOCH: 3, CURRENT LOSS: 0.44536933302879333, TIME TAKEN: 1.6330859661102295\n",
            "EPOCH: 4, CURRENT LOSS: 0.3602181673049927, TIME TAKEN: 1.6370105743408203\n",
            "EPOCH: 5, CURRENT LOSS: 0.3434361219406128, TIME TAKEN: 1.6418304443359375\n",
            "EPOCH: 6, CURRENT LOSS: 0.3133755624294281, TIME TAKEN: 1.6483700275421143\n",
            "EPOCH: 7, CURRENT LOSS: 0.3179498016834259, TIME TAKEN: 1.645374059677124\n",
            "EPOCH: 8, CURRENT LOSS: 0.3136201798915863, TIME TAKEN: 1.6467070579528809\n",
            "EPOCH: 9, CURRENT LOSS: 0.37999603152275085, TIME TAKEN: 1.644777774810791\n",
            "EPOCH: 10, CURRENT LOSS: 0.44640710949897766, TIME TAKEN: 1.6496837139129639\n",
            "EPOCH: 11, CURRENT LOSS: 0.4441677927970886, TIME TAKEN: 1.6481049060821533\n",
            "EPOCH: 12, CURRENT LOSS: 0.31326809525489807, TIME TAKEN: 1.649843692779541\n",
            "EPOCH: 13, CURRENT LOSS: 0.31326180696487427, TIME TAKEN: 1.6485333442687988\n",
            "EPOCH: 14, CURRENT LOSS: 0.38003844022750854, TIME TAKEN: 1.6447360515594482\n",
            "EPOCH: 15, CURRENT LOSS: 0.31586721539497375, TIME TAKEN: 1.6517977714538574\n",
            "EPOCH: 16, CURRENT LOSS: 0.3134840130805969, TIME TAKEN: 1.6481471061706543\n",
            "EPOCH: 17, CURRENT LOSS: 0.3801479935646057, TIME TAKEN: 1.6483666896820068\n",
            "EPOCH: 18, CURRENT LOSS: 0.4466018080711365, TIME TAKEN: 1.650879144668579\n",
            "EPOCH: 19, CURRENT LOSS: 0.37992826104164124, TIME TAKEN: 1.649235486984253\n",
            "EPOCH: 20, CURRENT LOSS: 0.37990325689315796, TIME TAKEN: 1.6454150676727295\n",
            "EPOCH: 21, CURRENT LOSS: 0.3192083537578583, TIME TAKEN: 1.6480121612548828\n",
            "EPOCH: 22, CURRENT LOSS: 0.3132929503917694, TIME TAKEN: 1.648026943206787\n",
            "EPOCH: 23, CURRENT LOSS: 0.379928320646286, TIME TAKEN: 1.647050142288208\n",
            "EPOCH: 24, CURRENT LOSS: 0.3132622539997101, TIME TAKEN: 1.6384246349334717\n",
            "EPOCH: 25, CURRENT LOSS: 0.3132704198360443, TIME TAKEN: 1.638737678527832\n",
            "EPOCH: 26, CURRENT LOSS: 0.3133310079574585, TIME TAKEN: 1.6473679542541504\n",
            "EPOCH: 27, CURRENT LOSS: 0.3132629692554474, TIME TAKEN: 1.646317958831787\n",
            "EPOCH: 28, CURRENT LOSS: 0.31329891085624695, TIME TAKEN: 1.6494662761688232\n",
            "EPOCH: 29, CURRENT LOSS: 0.379928320646286, TIME TAKEN: 1.6456549167633057\n",
            "accuracy: 0.875\n",
            "precision: 0.8821154622527251\n",
            "recall: 0.8677521842732328\n",
            "f1-score: 0.8748748748748749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model3B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5406274795532227, TIME TAKEN: 0.9773406982421875\n",
            "EPOCH: 1, CURRENT LOSS: 0.3141188323497772, TIME TAKEN: 0.9748246669769287\n",
            "EPOCH: 2, CURRENT LOSS: 0.5083272457122803, TIME TAKEN: 0.9771730899810791\n",
            "EPOCH: 3, CURRENT LOSS: 0.6484090685844421, TIME TAKEN: 0.966649055480957\n",
            "EPOCH: 4, CURRENT LOSS: 0.5771973729133606, TIME TAKEN: 0.9675281047821045\n",
            "EPOCH: 5, CURRENT LOSS: 0.46156787872314453, TIME TAKEN: 0.9735760688781738\n",
            "EPOCH: 6, CURRENT LOSS: 0.31326204538345337, TIME TAKEN: 0.9731500148773193\n",
            "EPOCH: 7, CURRENT LOSS: 0.4392170011997223, TIME TAKEN: 0.9923796653747559\n",
            "EPOCH: 8, CURRENT LOSS: 0.3135621249675751, TIME TAKEN: 0.9675509929656982\n",
            "EPOCH: 9, CURRENT LOSS: 0.5145688652992249, TIME TAKEN: 0.9717133045196533\n",
            "EPOCH: 10, CURRENT LOSS: 0.42084357142448425, TIME TAKEN: 0.963695764541626\n",
            "EPOCH: 11, CURRENT LOSS: 0.32293155789375305, TIME TAKEN: 0.9650943279266357\n",
            "EPOCH: 12, CURRENT LOSS: 0.5122740864753723, TIME TAKEN: 0.9649460315704346\n",
            "EPOCH: 13, CURRENT LOSS: 0.3799607455730438, TIME TAKEN: 0.9656317234039307\n",
            "EPOCH: 14, CURRENT LOSS: 0.31326597929000854, TIME TAKEN: 0.9683704376220703\n",
            "EPOCH: 15, CURRENT LOSS: 0.38487592339515686, TIME TAKEN: 0.9656944274902344\n",
            "EPOCH: 16, CURRENT LOSS: 0.4468929171562195, TIME TAKEN: 0.9681899547576904\n",
            "EPOCH: 17, CURRENT LOSS: 0.3799281418323517, TIME TAKEN: 0.967186450958252\n",
            "EPOCH: 18, CURRENT LOSS: 0.3133503198623657, TIME TAKEN: 0.9712893962860107\n",
            "EPOCH: 19, CURRENT LOSS: 0.31408002972602844, TIME TAKEN: 0.9691317081451416\n",
            "EPOCH: 20, CURRENT LOSS: 0.31326156854629517, TIME TAKEN: 0.9790744781494141\n",
            "EPOCH: 21, CURRENT LOSS: 0.3136410415172577, TIME TAKEN: 0.9754364490509033\n",
            "EPOCH: 22, CURRENT LOSS: 0.514110803604126, TIME TAKEN: 0.9695565700531006\n",
            "EPOCH: 23, CURRENT LOSS: 0.31328317523002625, TIME TAKEN: 0.9777953624725342\n",
            "EPOCH: 24, CURRENT LOSS: 0.31327107548713684, TIME TAKEN: 0.9853308200836182\n",
            "EPOCH: 25, CURRENT LOSS: 0.3133193254470825, TIME TAKEN: 0.9744048118591309\n",
            "EPOCH: 26, CURRENT LOSS: 0.3132738769054413, TIME TAKEN: 0.9652867317199707\n",
            "EPOCH: 27, CURRENT LOSS: 0.3812706768512726, TIME TAKEN: 0.9669673442840576\n",
            "EPOCH: 28, CURRENT LOSS: 0.38013964891433716, TIME TAKEN: 0.9626445770263672\n",
            "EPOCH: 29, CURRENT LOSS: 0.31326159834861755, TIME TAKEN: 0.968543529510498\n",
            "accuracy: 0.8246\n",
            "precision: 0.7640811071773415\n",
            "recall: 0.9428117553613979\n",
            "f1-score: 0.8440888888888889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model4A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5330668091773987, TIME TAKEN: 1.0517768859863281\n",
            "EPOCH: 1, CURRENT LOSS: 0.3300681710243225, TIME TAKEN: 0.9487504959106445\n",
            "EPOCH: 2, CURRENT LOSS: 0.4329375922679901, TIME TAKEN: 0.9448103904724121\n",
            "EPOCH: 3, CURRENT LOSS: 0.32031071186065674, TIME TAKEN: 0.944251298904419\n",
            "EPOCH: 4, CURRENT LOSS: 0.4489659070968628, TIME TAKEN: 0.9480500221252441\n",
            "EPOCH: 5, CURRENT LOSS: 0.36036238074302673, TIME TAKEN: 0.9444561004638672\n",
            "EPOCH: 6, CURRENT LOSS: 0.3173307776451111, TIME TAKEN: 0.9489724636077881\n",
            "EPOCH: 7, CURRENT LOSS: 0.38018980622291565, TIME TAKEN: 0.951371431350708\n",
            "EPOCH: 8, CURRENT LOSS: 0.4579981863498688, TIME TAKEN: 0.9506371021270752\n",
            "EPOCH: 9, CURRENT LOSS: 0.31328290700912476, TIME TAKEN: 0.9558804035186768\n",
            "EPOCH: 10, CURRENT LOSS: 0.579826295375824, TIME TAKEN: 0.95294189453125\n",
            "EPOCH: 11, CURRENT LOSS: 0.4146033227443695, TIME TAKEN: 0.9551267623901367\n",
            "EPOCH: 12, CURRENT LOSS: 0.3823249936103821, TIME TAKEN: 0.9570941925048828\n",
            "EPOCH: 13, CURRENT LOSS: 0.3821164667606354, TIME TAKEN: 0.9485383033752441\n",
            "EPOCH: 14, CURRENT LOSS: 0.3803543448448181, TIME TAKEN: 0.9473056793212891\n",
            "EPOCH: 15, CURRENT LOSS: 0.31326812505722046, TIME TAKEN: 0.9493272304534912\n",
            "EPOCH: 16, CURRENT LOSS: 0.32445651292800903, TIME TAKEN: 0.9506897926330566\n",
            "EPOCH: 17, CURRENT LOSS: 0.3799281716346741, TIME TAKEN: 0.9528682231903076\n",
            "EPOCH: 18, CURRENT LOSS: 0.44676393270492554, TIME TAKEN: 0.9571685791015625\n",
            "EPOCH: 19, CURRENT LOSS: 0.3809695541858673, TIME TAKEN: 0.9535236358642578\n",
            "EPOCH: 20, CURRENT LOSS: 0.3133368194103241, TIME TAKEN: 0.9553887844085693\n",
            "EPOCH: 21, CURRENT LOSS: 0.3144053816795349, TIME TAKEN: 0.9550273418426514\n",
            "EPOCH: 22, CURRENT LOSS: 0.32305532693862915, TIME TAKEN: 0.9545562267303467\n",
            "EPOCH: 23, CURRENT LOSS: 0.44925248622894287, TIME TAKEN: 0.9563534259796143\n",
            "EPOCH: 24, CURRENT LOSS: 0.35886648297309875, TIME TAKEN: 0.9543516635894775\n",
            "EPOCH: 25, CURRENT LOSS: 0.38002967834472656, TIME TAKEN: 0.9557235240936279\n",
            "EPOCH: 26, CURRENT LOSS: 0.37995249032974243, TIME TAKEN: 0.9571747779846191\n",
            "EPOCH: 27, CURRENT LOSS: 0.3132619261741638, TIME TAKEN: 0.9584066867828369\n",
            "EPOCH: 28, CURRENT LOSS: 0.3734094202518463, TIME TAKEN: 0.956841230392456\n",
            "EPOCH: 29, CURRENT LOSS: 0.31326189637184143, TIME TAKEN: 0.9536325931549072\n",
            "accuracy: 0.862\n",
            "precision: 0.8347985347985348\n",
            "recall: 0.9050833995234313\n",
            "f1-score: 0.8685213414634146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model4B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.45271286368370056, TIME TAKEN: 0.9417886734008789\n",
            "EPOCH: 1, CURRENT LOSS: 0.5282237529754639, TIME TAKEN: 0.9403643608093262\n",
            "EPOCH: 2, CURRENT LOSS: 0.5082405209541321, TIME TAKEN: 0.9413857460021973\n",
            "EPOCH: 3, CURRENT LOSS: 0.37976473569869995, TIME TAKEN: 0.938896894454956\n",
            "EPOCH: 4, CURRENT LOSS: 0.3132823705673218, TIME TAKEN: 0.940377950668335\n",
            "EPOCH: 5, CURRENT LOSS: 0.3457786440849304, TIME TAKEN: 0.9395773410797119\n",
            "EPOCH: 6, CURRENT LOSS: 0.4428996443748474, TIME TAKEN: 0.9293239116668701\n",
            "EPOCH: 7, CURRENT LOSS: 0.4945010840892792, TIME TAKEN: 0.9304003715515137\n",
            "EPOCH: 8, CURRENT LOSS: 0.3212987184524536, TIME TAKEN: 0.9333658218383789\n",
            "EPOCH: 9, CURRENT LOSS: 0.5490754842758179, TIME TAKEN: 0.9323625564575195\n",
            "EPOCH: 10, CURRENT LOSS: 0.3132726848125458, TIME TAKEN: 0.9393908977508545\n",
            "EPOCH: 11, CURRENT LOSS: 0.42842695116996765, TIME TAKEN: 0.9405093193054199\n",
            "EPOCH: 12, CURRENT LOSS: 0.33704498410224915, TIME TAKEN: 0.9431829452514648\n",
            "EPOCH: 13, CURRENT LOSS: 0.3898838460445404, TIME TAKEN: 0.9407055377960205\n",
            "EPOCH: 14, CURRENT LOSS: 0.3135039508342743, TIME TAKEN: 0.9416477680206299\n",
            "EPOCH: 15, CURRENT LOSS: 0.38000625371932983, TIME TAKEN: 0.9409363269805908\n",
            "EPOCH: 16, CURRENT LOSS: 0.48112455010414124, TIME TAKEN: 0.9405238628387451\n",
            "EPOCH: 17, CURRENT LOSS: 0.420798659324646, TIME TAKEN: 0.9412727355957031\n",
            "EPOCH: 18, CURRENT LOSS: 0.3799223005771637, TIME TAKEN: 0.9422693252563477\n",
            "EPOCH: 19, CURRENT LOSS: 0.31569400429725647, TIME TAKEN: 0.9372601509094238\n",
            "EPOCH: 20, CURRENT LOSS: 0.4221985936164856, TIME TAKEN: 0.9414889812469482\n",
            "EPOCH: 21, CURRENT LOSS: 0.3622051179409027, TIME TAKEN: 0.9420547485351562\n",
            "EPOCH: 22, CURRENT LOSS: 0.3147124648094177, TIME TAKEN: 0.9398891925811768\n",
            "EPOCH: 23, CURRENT LOSS: 0.3133932650089264, TIME TAKEN: 0.940096378326416\n",
            "EPOCH: 24, CURRENT LOSS: 0.37995344400405884, TIME TAKEN: 0.9415163993835449\n",
            "EPOCH: 25, CURRENT LOSS: 0.31326165795326233, TIME TAKEN: 0.9382600784301758\n",
            "EPOCH: 26, CURRENT LOSS: 0.3805930018424988, TIME TAKEN: 0.9348757266998291\n",
            "EPOCH: 27, CURRENT LOSS: 0.4479360282421112, TIME TAKEN: 0.933081865310669\n",
            "EPOCH: 28, CURRENT LOSS: 0.3133341372013092, TIME TAKEN: 0.9346544742584229\n",
            "EPOCH: 29, CURRENT LOSS: 0.31341490149497986, TIME TAKEN: 0.9361193180084229\n",
            "accuracy: 0.868\n",
            "precision: 0.8832508250825083\n",
            "recall: 0.8502779984114377\n",
            "f1-score: 0.8664508296236342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model4C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5273498892784119, TIME TAKEN: 1.086629867553711\n",
            "EPOCH: 1, CURRENT LOSS: 0.6271002888679504, TIME TAKEN: 1.0723049640655518\n",
            "EPOCH: 2, CURRENT LOSS: 0.3821227252483368, TIME TAKEN: 1.0634050369262695\n",
            "EPOCH: 3, CURRENT LOSS: 0.31730642914772034, TIME TAKEN: 1.0658724308013916\n",
            "EPOCH: 4, CURRENT LOSS: 0.38155901432037354, TIME TAKEN: 1.0495359897613525\n",
            "EPOCH: 5, CURRENT LOSS: 0.35649168491363525, TIME TAKEN: 1.0557904243469238\n",
            "EPOCH: 6, CURRENT LOSS: 0.3971358835697174, TIME TAKEN: 1.060783863067627\n",
            "EPOCH: 7, CURRENT LOSS: 0.4897383451461792, TIME TAKEN: 1.0577459335327148\n",
            "EPOCH: 8, CURRENT LOSS: 0.5134008526802063, TIME TAKEN: 1.0548536777496338\n",
            "EPOCH: 9, CURRENT LOSS: 0.32918164134025574, TIME TAKEN: 1.0570757389068604\n",
            "EPOCH: 10, CURRENT LOSS: 0.3136194050312042, TIME TAKEN: 1.0611472129821777\n",
            "EPOCH: 11, CURRENT LOSS: 0.3873688578605652, TIME TAKEN: 1.0593161582946777\n",
            "EPOCH: 12, CURRENT LOSS: 0.3994993269443512, TIME TAKEN: 1.0547142028808594\n",
            "EPOCH: 13, CURRENT LOSS: 0.3796645700931549, TIME TAKEN: 1.0660021305084229\n",
            "EPOCH: 14, CURRENT LOSS: 0.3803250193595886, TIME TAKEN: 1.0693185329437256\n",
            "EPOCH: 15, CURRENT LOSS: 0.31329748034477234, TIME TAKEN: 1.0774998664855957\n",
            "EPOCH: 16, CURRENT LOSS: 0.31345638632774353, TIME TAKEN: 1.0604102611541748\n",
            "EPOCH: 17, CURRENT LOSS: 0.43682655692100525, TIME TAKEN: 1.0705060958862305\n",
            "EPOCH: 18, CURRENT LOSS: 0.3133600056171417, TIME TAKEN: 1.0601356029510498\n",
            "EPOCH: 19, CURRENT LOSS: 0.31341326236724854, TIME TAKEN: 1.071272611618042\n",
            "EPOCH: 20, CURRENT LOSS: 0.3145318627357483, TIME TAKEN: 1.0817451477050781\n",
            "EPOCH: 21, CURRENT LOSS: 0.38024455308914185, TIME TAKEN: 1.070075511932373\n",
            "EPOCH: 22, CURRENT LOSS: 0.4465915858745575, TIME TAKEN: 1.0576539039611816\n",
            "EPOCH: 23, CURRENT LOSS: 0.3132617771625519, TIME TAKEN: 1.0566012859344482\n",
            "EPOCH: 24, CURRENT LOSS: 0.31326502561569214, TIME TAKEN: 1.0592997074127197\n",
            "EPOCH: 25, CURRENT LOSS: 0.44658777117729187, TIME TAKEN: 1.055818796157837\n",
            "EPOCH: 26, CURRENT LOSS: 0.3795999586582184, TIME TAKEN: 1.055251121520996\n",
            "EPOCH: 27, CURRENT LOSS: 0.382610023021698, TIME TAKEN: 1.0624701976776123\n",
            "EPOCH: 28, CURRENT LOSS: 0.31326156854629517, TIME TAKEN: 1.0606133937835693\n",
            "EPOCH: 29, CURRENT LOSS: 0.3799230754375458, TIME TAKEN: 1.0570752620697021\n",
            "accuracy: 0.8724\n",
            "precision: 0.9023972602739726\n",
            "recall: 0.8371723590150913\n",
            "f1-score: 0.8685620107128141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model5A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4320680499076843, TIME TAKEN: 1.0860633850097656\n",
            "EPOCH: 1, CURRENT LOSS: 0.604381263256073, TIME TAKEN: 1.0531611442565918\n",
            "EPOCH: 2, CURRENT LOSS: 0.33698081970214844, TIME TAKEN: 1.0628752708435059\n",
            "EPOCH: 3, CURRENT LOSS: 0.38747352361679077, TIME TAKEN: 1.068392276763916\n",
            "EPOCH: 4, CURRENT LOSS: 0.31640371680259705, TIME TAKEN: 1.0571603775024414\n",
            "EPOCH: 5, CURRENT LOSS: 0.3134991526603699, TIME TAKEN: 1.061858892440796\n",
            "EPOCH: 6, CURRENT LOSS: 0.41489142179489136, TIME TAKEN: 1.05653977394104\n",
            "EPOCH: 7, CURRENT LOSS: 0.4054487347602844, TIME TAKEN: 1.0787947177886963\n",
            "EPOCH: 8, CURRENT LOSS: 0.31362852454185486, TIME TAKEN: 1.0750503540039062\n",
            "EPOCH: 9, CURRENT LOSS: 0.5041995644569397, TIME TAKEN: 1.0747196674346924\n",
            "EPOCH: 10, CURRENT LOSS: 0.3743757903575897, TIME TAKEN: 1.0713937282562256\n",
            "EPOCH: 11, CURRENT LOSS: 0.34036025404930115, TIME TAKEN: 1.0626347064971924\n",
            "EPOCH: 12, CURRENT LOSS: 0.3278657793998718, TIME TAKEN: 1.0678346157073975\n",
            "EPOCH: 13, CURRENT LOSS: 0.44700443744659424, TIME TAKEN: 1.0593888759613037\n",
            "EPOCH: 14, CURRENT LOSS: 0.44658163189888, TIME TAKEN: 1.056328535079956\n",
            "EPOCH: 15, CURRENT LOSS: 0.3802375793457031, TIME TAKEN: 1.0594024658203125\n",
            "EPOCH: 16, CURRENT LOSS: 0.31455183029174805, TIME TAKEN: 1.054163932800293\n",
            "EPOCH: 17, CURRENT LOSS: 0.3800760507583618, TIME TAKEN: 1.0598640441894531\n",
            "EPOCH: 18, CURRENT LOSS: 0.37994518876075745, TIME TAKEN: 1.054319143295288\n",
            "EPOCH: 19, CURRENT LOSS: 0.31334319710731506, TIME TAKEN: 1.0576486587524414\n",
            "EPOCH: 20, CURRENT LOSS: 0.3799505829811096, TIME TAKEN: 1.057190179824829\n",
            "EPOCH: 21, CURRENT LOSS: 0.5799378752708435, TIME TAKEN: 1.0628249645233154\n",
            "EPOCH: 22, CURRENT LOSS: 0.3813941776752472, TIME TAKEN: 1.0607624053955078\n",
            "EPOCH: 23, CURRENT LOSS: 0.4582565128803253, TIME TAKEN: 1.0630528926849365\n",
            "EPOCH: 24, CURRENT LOSS: 0.3821161985397339, TIME TAKEN: 1.0641679763793945\n",
            "EPOCH: 25, CURRENT LOSS: 0.31330135464668274, TIME TAKEN: 1.071077823638916\n",
            "EPOCH: 26, CURRENT LOSS: 0.3132851719856262, TIME TAKEN: 1.0659468173980713\n",
            "EPOCH: 27, CURRENT LOSS: 0.3132835030555725, TIME TAKEN: 1.0672352313995361\n",
            "EPOCH: 28, CURRENT LOSS: 0.4221395254135132, TIME TAKEN: 1.0616531372070312\n",
            "EPOCH: 29, CURRENT LOSS: 0.31329306960105896, TIME TAKEN: 1.0686230659484863\n",
            "accuracy: 0.8742\n",
            "precision: 0.8755467196819086\n",
            "recall: 0.8745035742652899\n",
            "f1-score: 0.8750248360818598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model5B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.689972996711731, TIME TAKEN: 1.0946557521820068\n",
            "EPOCH: 1, CURRENT LOSS: 0.6923883557319641, TIME TAKEN: 1.0861799716949463\n",
            "EPOCH: 2, CURRENT LOSS: 0.6946315765380859, TIME TAKEN: 1.086698293685913\n",
            "EPOCH: 3, CURRENT LOSS: 0.6952884197235107, TIME TAKEN: 1.0747385025024414\n",
            "EPOCH: 4, CURRENT LOSS: 0.692973792552948, TIME TAKEN: 1.0681853294372559\n",
            "EPOCH: 5, CURRENT LOSS: 0.693926990032196, TIME TAKEN: 1.068166732788086\n",
            "EPOCH: 6, CURRENT LOSS: 0.692601203918457, TIME TAKEN: 1.071789264678955\n",
            "EPOCH: 7, CURRENT LOSS: 0.6889458894729614, TIME TAKEN: 1.0691065788269043\n",
            "EPOCH: 8, CURRENT LOSS: 0.6929682493209839, TIME TAKEN: 1.0636353492736816\n",
            "EPOCH: 9, CURRENT LOSS: 0.6958452463150024, TIME TAKEN: 1.0716118812561035\n",
            "EPOCH: 10, CURRENT LOSS: 0.695460855960846, TIME TAKEN: 1.069098949432373\n",
            "EPOCH: 11, CURRENT LOSS: 0.693338930606842, TIME TAKEN: 1.0727486610412598\n",
            "EPOCH: 12, CURRENT LOSS: 0.6919881105422974, TIME TAKEN: 1.0680303573608398\n",
            "EPOCH: 13, CURRENT LOSS: 0.6926270127296448, TIME TAKEN: 1.0685386657714844\n",
            "EPOCH: 14, CURRENT LOSS: 0.7055772542953491, TIME TAKEN: 1.07330322265625\n",
            "EPOCH: 15, CURRENT LOSS: 0.6695044636726379, TIME TAKEN: 1.0701818466186523\n",
            "EPOCH: 16, CURRENT LOSS: 0.6954347491264343, TIME TAKEN: 1.080287218093872\n",
            "EPOCH: 17, CURRENT LOSS: 0.6955646276473999, TIME TAKEN: 1.0711047649383545\n",
            "EPOCH: 18, CURRENT LOSS: 0.6914322972297668, TIME TAKEN: 1.072826623916626\n",
            "EPOCH: 19, CURRENT LOSS: 0.6758384704589844, TIME TAKEN: 1.0757191181182861\n",
            "EPOCH: 20, CURRENT LOSS: 0.6699196100234985, TIME TAKEN: 1.0755934715270996\n",
            "EPOCH: 21, CURRENT LOSS: 0.6804784536361694, TIME TAKEN: 1.1483006477355957\n",
            "EPOCH: 22, CURRENT LOSS: 0.5513557195663452, TIME TAKEN: 1.1382927894592285\n",
            "EPOCH: 23, CURRENT LOSS: 0.576038122177124, TIME TAKEN: 1.1506316661834717\n",
            "EPOCH: 24, CURRENT LOSS: 0.521028459072113, TIME TAKEN: 1.137986183166504\n",
            "EPOCH: 25, CURRENT LOSS: 0.5174797177314758, TIME TAKEN: 1.1411821842193604\n",
            "EPOCH: 26, CURRENT LOSS: 0.5640079975128174, TIME TAKEN: 1.1391873359680176\n",
            "EPOCH: 27, CURRENT LOSS: 0.39725637435913086, TIME TAKEN: 1.1401700973510742\n",
            "EPOCH: 28, CURRENT LOSS: 0.446292906999588, TIME TAKEN: 1.1379303932189941\n",
            "EPOCH: 29, CURRENT LOSS: 0.4622093141078949, TIME TAKEN: 1.1416022777557373\n",
            "accuracy: 0.8428\n",
            "precision: 0.8042867182009839\n",
            "recall: 0.9090548054011119\n",
            "f1-score: 0.8534675615212528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model5C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.3782714605331421, TIME TAKEN: 1.0298242568969727\n",
            "EPOCH: 1, CURRENT LOSS: 0.6383500695228577, TIME TAKEN: 1.0161356925964355\n",
            "EPOCH: 2, CURRENT LOSS: 0.32184645533561707, TIME TAKEN: 1.021418809890747\n",
            "EPOCH: 3, CURRENT LOSS: 0.39537543058395386, TIME TAKEN: 1.0099923610687256\n",
            "EPOCH: 4, CURRENT LOSS: 0.3844519555568695, TIME TAKEN: 1.0105054378509521\n",
            "EPOCH: 5, CURRENT LOSS: 0.3820784389972687, TIME TAKEN: 1.0088577270507812\n",
            "EPOCH: 6, CURRENT LOSS: 0.4261283874511719, TIME TAKEN: 1.0145339965820312\n",
            "EPOCH: 7, CURRENT LOSS: 0.32001733779907227, TIME TAKEN: 1.0114848613739014\n",
            "EPOCH: 8, CURRENT LOSS: 0.3800651729106903, TIME TAKEN: 1.0104825496673584\n",
            "EPOCH: 9, CURRENT LOSS: 0.37986183166503906, TIME TAKEN: 1.008582592010498\n",
            "EPOCH: 10, CURRENT LOSS: 0.5742501616477966, TIME TAKEN: 1.0040183067321777\n",
            "EPOCH: 11, CURRENT LOSS: 0.39384034276008606, TIME TAKEN: 1.023604154586792\n",
            "EPOCH: 12, CURRENT LOSS: 0.3801092207431793, TIME TAKEN: 1.0144531726837158\n",
            "EPOCH: 13, CURRENT LOSS: 0.3547631800174713, TIME TAKEN: 1.033576250076294\n",
            "EPOCH: 14, CURRENT LOSS: 0.38406723737716675, TIME TAKEN: 1.014949083328247\n",
            "EPOCH: 15, CURRENT LOSS: 0.31334397196769714, TIME TAKEN: 1.0091345310211182\n",
            "EPOCH: 16, CURRENT LOSS: 0.4466029107570648, TIME TAKEN: 1.0096850395202637\n",
            "EPOCH: 17, CURRENT LOSS: 0.4938364624977112, TIME TAKEN: 1.0111100673675537\n",
            "EPOCH: 18, CURRENT LOSS: 0.31377461552619934, TIME TAKEN: 1.0054795742034912\n",
            "EPOCH: 19, CURRENT LOSS: 0.3248146176338196, TIME TAKEN: 1.002528429031372\n",
            "EPOCH: 20, CURRENT LOSS: 0.31328603625297546, TIME TAKEN: 1.004457950592041\n",
            "EPOCH: 21, CURRENT LOSS: 0.31394702196121216, TIME TAKEN: 1.0087387561798096\n",
            "EPOCH: 22, CURRENT LOSS: 0.3133673369884491, TIME TAKEN: 1.0064477920532227\n",
            "EPOCH: 23, CURRENT LOSS: 0.31326237320899963, TIME TAKEN: 1.0146067142486572\n",
            "EPOCH: 24, CURRENT LOSS: 0.31334713101387024, TIME TAKEN: 1.0092754364013672\n",
            "EPOCH: 25, CURRENT LOSS: 0.3799285292625427, TIME TAKEN: 1.0234434604644775\n",
            "EPOCH: 26, CURRENT LOSS: 0.313263863325119, TIME TAKEN: 1.019256591796875\n",
            "EPOCH: 27, CURRENT LOSS: 0.322348415851593, TIME TAKEN: 1.016941785812378\n",
            "EPOCH: 28, CURRENT LOSS: 0.3147071897983551, TIME TAKEN: 1.0072963237762451\n",
            "EPOCH: 29, CURRENT LOSS: 0.5159088373184204, TIME TAKEN: 1.0103960037231445\n",
            "accuracy: 0.8234\n",
            "precision: 0.7651638014920532\n",
            "recall: 0.9368546465448769\n",
            "f1-score: 0.8423495804320659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model7A. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.5904111862182617, TIME TAKEN: 1.0195605754852295\n",
            "EPOCH: 1, CURRENT LOSS: 0.45038992166519165, TIME TAKEN: 1.006758213043213\n",
            "EPOCH: 2, CURRENT LOSS: 0.3857126533985138, TIME TAKEN: 1.009338617324829\n",
            "EPOCH: 3, CURRENT LOSS: 0.3808403015136719, TIME TAKEN: 1.0106191635131836\n",
            "EPOCH: 4, CURRENT LOSS: 0.47566378116607666, TIME TAKEN: 1.011232852935791\n",
            "EPOCH: 5, CURRENT LOSS: 0.4285326302051544, TIME TAKEN: 1.0132973194122314\n",
            "EPOCH: 6, CURRENT LOSS: 0.507980465888977, TIME TAKEN: 1.0046637058258057\n",
            "EPOCH: 7, CURRENT LOSS: 0.489962637424469, TIME TAKEN: 1.0081157684326172\n",
            "EPOCH: 8, CURRENT LOSS: 0.3139623999595642, TIME TAKEN: 1.0113391876220703\n",
            "EPOCH: 9, CURRENT LOSS: 0.3710188865661621, TIME TAKEN: 1.0115845203399658\n",
            "EPOCH: 10, CURRENT LOSS: 0.31501108407974243, TIME TAKEN: 1.0130786895751953\n",
            "EPOCH: 11, CURRENT LOSS: 0.35876771807670593, TIME TAKEN: 1.0078303813934326\n",
            "EPOCH: 12, CURRENT LOSS: 0.31350526213645935, TIME TAKEN: 1.004371166229248\n",
            "EPOCH: 13, CURRENT LOSS: 0.4027003049850464, TIME TAKEN: 1.010260820388794\n",
            "EPOCH: 14, CURRENT LOSS: 0.31327009201049805, TIME TAKEN: 1.0044691562652588\n",
            "EPOCH: 15, CURRENT LOSS: 0.4685865044593811, TIME TAKEN: 1.011533260345459\n",
            "EPOCH: 16, CURRENT LOSS: 0.44670259952545166, TIME TAKEN: 1.0042986869812012\n",
            "EPOCH: 17, CURRENT LOSS: 0.3139234483242035, TIME TAKEN: 1.008519172668457\n",
            "EPOCH: 18, CURRENT LOSS: 0.3132694959640503, TIME TAKEN: 1.0148613452911377\n",
            "EPOCH: 19, CURRENT LOSS: 0.5114446878433228, TIME TAKEN: 1.0173308849334717\n",
            "EPOCH: 20, CURRENT LOSS: 0.31329435110092163, TIME TAKEN: 1.0148324966430664\n",
            "EPOCH: 21, CURRENT LOSS: 0.3798331618309021, TIME TAKEN: 1.0139670372009277\n",
            "EPOCH: 22, CURRENT LOSS: 0.3886658549308777, TIME TAKEN: 1.0102553367614746\n",
            "EPOCH: 23, CURRENT LOSS: 0.38031986355781555, TIME TAKEN: 1.011664867401123\n",
            "EPOCH: 24, CURRENT LOSS: 0.31329721212387085, TIME TAKEN: 1.0065734386444092\n",
            "EPOCH: 25, CURRENT LOSS: 0.31479117274284363, TIME TAKEN: 1.0145413875579834\n",
            "EPOCH: 26, CURRENT LOSS: 0.3439919054508209, TIME TAKEN: 1.0182697772979736\n",
            "EPOCH: 27, CURRENT LOSS: 0.3133285343647003, TIME TAKEN: 1.007601022720337\n",
            "EPOCH: 28, CURRENT LOSS: 0.3135494291782379, TIME TAKEN: 1.0069305896759033\n",
            "EPOCH: 29, CURRENT LOSS: 0.3767502009868622, TIME TAKEN: 1.0026004314422607\n",
            "accuracy: 0.8304\n",
            "precision: 0.7726975832789027\n",
            "recall: 0.9396346306592533\n",
            "f1-score: 0.8480286738351255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model7B. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.4369955360889435, TIME TAKEN: 1.0206513404846191\n",
            "EPOCH: 1, CURRENT LOSS: 0.4234408438205719, TIME TAKEN: 1.0068368911743164\n",
            "EPOCH: 2, CURRENT LOSS: 0.5136333703994751, TIME TAKEN: 1.010990858078003\n",
            "EPOCH: 3, CURRENT LOSS: 0.5131607055664062, TIME TAKEN: 1.0046420097351074\n",
            "EPOCH: 4, CURRENT LOSS: 0.51754230260849, TIME TAKEN: 1.0104196071624756\n",
            "EPOCH: 5, CURRENT LOSS: 0.37348267436027527, TIME TAKEN: 1.0032331943511963\n",
            "EPOCH: 6, CURRENT LOSS: 0.35635676980018616, TIME TAKEN: 1.0061759948730469\n",
            "EPOCH: 7, CURRENT LOSS: 0.3177572190761566, TIME TAKEN: 1.0051546096801758\n",
            "EPOCH: 8, CURRENT LOSS: 0.4328053295612335, TIME TAKEN: 1.009512186050415\n",
            "EPOCH: 9, CURRENT LOSS: 0.38060396909713745, TIME TAKEN: 1.0092813968658447\n",
            "EPOCH: 10, CURRENT LOSS: 0.5168617963790894, TIME TAKEN: 1.087310791015625\n",
            "EPOCH: 11, CURRENT LOSS: 0.3211657702922821, TIME TAKEN: 1.082632303237915\n",
            "EPOCH: 12, CURRENT LOSS: 0.38013219833374023, TIME TAKEN: 1.0754954814910889\n",
            "EPOCH: 13, CURRENT LOSS: 0.32445013523101807, TIME TAKEN: 1.0766408443450928\n",
            "EPOCH: 14, CURRENT LOSS: 0.31329065561294556, TIME TAKEN: 1.0779752731323242\n",
            "EPOCH: 15, CURRENT LOSS: 0.4466419219970703, TIME TAKEN: 1.0223212242126465\n",
            "EPOCH: 16, CURRENT LOSS: 0.3751074969768524, TIME TAKEN: 1.009096622467041\n",
            "EPOCH: 17, CURRENT LOSS: 0.3797720670700073, TIME TAKEN: 1.0076696872711182\n",
            "EPOCH: 18, CURRENT LOSS: 0.3134203851222992, TIME TAKEN: 1.006216287612915\n",
            "EPOCH: 19, CURRENT LOSS: 0.3696345388889313, TIME TAKEN: 1.017005443572998\n",
            "EPOCH: 20, CURRENT LOSS: 0.3134438097476959, TIME TAKEN: 1.006359577178955\n",
            "EPOCH: 21, CURRENT LOSS: 0.3133592903614044, TIME TAKEN: 1.005133867263794\n",
            "EPOCH: 22, CURRENT LOSS: 0.3799385726451874, TIME TAKEN: 1.0147244930267334\n",
            "EPOCH: 23, CURRENT LOSS: 0.31378936767578125, TIME TAKEN: 1.0115809440612793\n",
            "EPOCH: 24, CURRENT LOSS: 0.37357574701309204, TIME TAKEN: 1.0105397701263428\n",
            "EPOCH: 25, CURRENT LOSS: 0.38009166717529297, TIME TAKEN: 1.0111417770385742\n",
            "EPOCH: 26, CURRENT LOSS: 0.3132646381855011, TIME TAKEN: 1.009178638458252\n",
            "EPOCH: 27, CURRENT LOSS: 0.3335433304309845, TIME TAKEN: 1.0093410015106201\n",
            "EPOCH: 28, CURRENT LOSS: 0.44788995385169983, TIME TAKEN: 1.0117878913879395\n",
            "EPOCH: 29, CURRENT LOSS: 0.3133937418460846, TIME TAKEN: 1.0053908824920654\n",
            "accuracy: 0.8604\n",
            "precision: 0.8233830845771144\n",
            "recall: 0.9201747418586179\n",
            "f1-score: 0.8690922730682671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Model7C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZDP0j9klAf9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdl_1a = torch.load('Model7B.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0ZU0noHFDSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validate(mdl_1a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDSIMKxpwa4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "42264ee3-9d01-439a-957b-fdc5eb1e8d7c"
      },
      "cell_type": "code",
      "source": [
        "list = np.arange(15).reshape(3,-1)\n",
        "list"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4],\n",
              "       [ 5,  6,  7,  8,  9],\n",
              "       [10, 11, 12, 13, 14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "metadata": {
        "id": "EdBK2fh5wj31",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = torch.tensor(list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axtD1TrZwvmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b8ef904e-47f9-416e-ee8e-ee10f9462081"
      },
      "cell_type": "code",
      "source": [
        "list1 = np.arange(5)\n",
        "list2 = np.arange(5,10)\n",
        "list3 = np.arange(10,15)\n",
        "list1 = torch.tensor(list1)\n",
        "list2 = torch.tensor(list2)\n",
        "list3 = torch.tensor(list3)\n",
        "list = [list1, list2, list3]\n",
        "list"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2, 3, 4]),\n",
              " tensor([5, 6, 7, 8, 9]),\n",
              " tensor([10, 11, 12, 13, 14])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "metadata": {
        "id": "98MMpAyoxXKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "675cd486-3500-4a83-cbc5-4954fe47e6b7"
      },
      "cell_type": "code",
      "source": [
        "list1.numpy()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_IJTshexmeX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2732959a-4e87-480e-9e5a-df9000684f23"
      },
      "cell_type": "code",
      "source": [
        "list = [list1.numpy(), list2.numpy(), list3.numpy()]\n",
        "list"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2, 3, 4]), array([5, 6, 7, 8, 9]), array([10, 11, 12, 13, 14])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    }
  ]
}