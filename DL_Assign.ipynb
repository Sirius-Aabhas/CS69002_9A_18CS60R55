{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirius-Aabhas/CS69002_9A_18CS60R55/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bRuGSGqnMOXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijrEth3MRQ6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data"
      ]
    },
    {
      "metadata": {
        "id": "J5ITVAYmiy5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQLFDGIQjrh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Train_20K.csv'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7sqK9HKoGzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3VpG5_h1oKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data for now"
      ]
    },
    {
      "metadata": {
        "id": "pHXKubc019hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0ac0d82b-726f-4524-ff26-b7b9628f3ad8"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train_20K.csv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Waters has given us a genuinely enjoyable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This first two seasons of this comedy series w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What an unfortunate mess is \"Shiner.\" I wanted...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm not entirely sure Rob Schmidt qualifies as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i wasn't sure whether to laugh or cry. Porrett...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  John Waters has given us a genuinely enjoyable...      1\n",
              "1  This first two seasons of this comedy series w...      1\n",
              "2  What an unfortunate mess is \"Shiner.\" I wanted...      0\n",
              "3  I'm not entirely sure Rob Schmidt qualifies as...      1\n",
              "4  i wasn't sure whether to laugh or cry. Porrett...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "Gpv07aqq0wJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f703c9f9-fad3-439d-851f-5fb1bdbaa644"
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('Test_5K.csv', sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>as always this is an inaccurate picture of the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did the movie-makers even preview this before ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Heavily re-edited and often confusing, the ori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I notice that most of the people who think thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First of all, this is a low-budget movie, so m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  as always this is an inaccurate picture of the...      0\n",
              "1  Did the movie-makers even preview this before ...      0\n",
              "2  Heavily re-edited and often confusing, the ori...      0\n",
              "3  I notice that most of the people who think thi...      0\n",
              "4  First of all, this is a low-budget movie, so m...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "zvXSxRtMNw8U",
        "colab_type": "code",
        "outputId": "c9c8fe8f-8b94-45e1-81fc-9213e308a018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df[df['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df[df['label']==1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rbQhm8mQ7BN",
        "colab_type": "code",
        "outputId": "ec2428b9-4717-4fd4-86f5-c5d58ad8418b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "print(text_reviews[0], text_labels[0])\n",
        "print(len(text_reviews), len(text_labels))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "john waters has given us a genuinely enjoyable film. this certainly isn't without its shocking waters-esque moments, but it is tamer than his older culty stuff, such as \"pink flamingoes\". \"pecker\" harkens back to john's early mainstream stage in that it reminds the viewer of the same kind of humor that was evident in \"polyester\". overall, a really fun comedy with some great moments! 1\n",
            "17999 17999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tOgBzlyA2znw",
        "colab_type": "code",
        "outputId": "0ba8cd2f-bb48-48c8-bc06-ea713c06399d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "data = [(text_reviews[i], text_labels[i])for i in range(len(text_labels))]\n",
        "data[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('john waters has given us a genuinely enjoyable film. this certainly isn\\'t without its shocking waters-esque moments, but it is tamer than his older culty stuff, such as \"pink flamingoes\". \"pecker\" harkens back to john\\'s early mainstream stage in that it reminds the viewer of the same kind of humor that was evident in \"polyester\". overall, a really fun comedy with some great moments!',\n",
              "  1),\n",
              " (\"this first two seasons of this comedy series were very strange and they weren't very funny and had a drama element where bill (the mother) was struggling with all the usual problems in life but that element was a bit depressing and didn't mix well with th comedy elements which is probably why it was dropped. after that it soon became one of the funniest comedy series the bbc have ever made! the chemistry between bill and ben's character's were very funny and there was always so many brilliant and memorable sketches in each series. the christmas specials were hilarious and a real treat for christmas. <br /><br />the show came to a stop when the main actor gary olsen playing bill passed away which was very sad because he was a brilliant actor in films such as up 'n' under and a very funny man rip<br /><br />this underrated show has sadly disappeared from our television screens and doesn't to be repeated that often - though it does appear on uktv gold once in a while but it should be repeated on bbc one or two to show this brilliant comedy to a new audience\",\n",
              "  1),\n",
              " ('what an unfortunate mess is \"shiner.\" i wanted to like this over-the-top, anti-film aspirant, and in fact found a number of moments with powerful resonance. sadly, those moments are few and far between. while i appreciate some of what calson was attempting, any advantage aspired to by bare bones, no budget cinematography was destroyed with some truly atrocious editing that benefited the movie not at all.<br /><br />while bad acting abounds in low budget (and big budget) cinema, shiner has some remarkably bad performances that are nearly painful to watch. in particular the \"straight\" couple linda and young guy. these are the two most poorly written characters offering almost nothing to the story. the acting is so abysmal and neither actor seems capable of resisting smirking or cracking up as they drearily drop their lines with an appalling lack of skill. the choppy editing almost lends the feeling that these roles were entirely gratuitous and dropped in to avoid the films being stereotypically cast as an oddball gay film. it would have been better off as such.<br /><br />with all that is going wrong for it, there are several performances that seem to capture what calson was hoping to get. in particular the story centering on bob and tim. these are the two most richly drawn characters and offer the most rewards with genuinely captivating performances by nicholas t. king (bob) and david zelinas (tim). tim is a boxer with some serious issues. remarkably low self esteem is disguised by an almost cartoon like arrogance that he wears like armour plating. obsessed with tim, the seemingly harmless yet ultimately creepy bob, stalks the boxer in classic cat-and-mouse fashion. when the tables are turned and hunter becomes the hunted, the resulting in the film\\'s only genuine emotional catharsis. in a film so artificially hard-edged (that\\'s a compliment) one character must have that revelatory break through (or breakdown, as the case proves here) and the final confrontation between bob and tim provide zelinas and king opportunity to display some real acting chops.<br /><br />as played by scott stepp and derris nile, tony and danny seem to be the focus of the movie, and despite some bravado moments of their own (including one truly disturbing scene revealing the sex/violence obsession), but they can\\'t seem to escape a cartoon-like artifice and it\\'s difficult to look at - or beyond their seeming one note symphony and find anything other than the obvious.<br /><br />ultimately this same raw material could (and should) be used to tell this story in better fashion. alas, there really isn\\'t much to recommend this yet, the performances by messrs. king and zelinas, really do offer something special and a glimpse of what might have been and are ultimately worth seeing.',\n",
              "  0),\n",
              " ('i\\'m not entirely sure rob schmidt qualifies as a \"master\" in the genre of horror, since he previously just directed one horror film called \"wrong turn\" and that one was actually just was slightly above mediocre, but fact is that he made with \"right to die\" one of the best and creepiest episodes of the entire second season of the \"masters of horror\" franchise. there was a similar underdog story in season one, when william malone made on of the best episodes with \"the fair haired child\" even though his other long feature films \"fear dot com\" and \"house on haunted hill\" sucked pretty badly.<br /><br />the story of \"right to die\" cleverly picks in on the nowadays piping hot social debate of euthanasia, but thankfully also features multiple old-fashioned horror themes like ghostly vengeance, murderous conspiracies, pitch black humor and comic book styled violence. whilst driving home late one night and discussing the husband\\'s continuous adultery, the addison couple are involved in a terrible car accident. cliff walks away from the wreck unharmed but his wife abby is fully burned and needs to be kept alive artificially. whilst cliff and his sleazy attorney (corbin bernsen of \"the dentist\") want to plug the plug on her and sue the car constructor, abbey\\'s mum sets up a giant media campaign to keep her daughter alive as a vegetable and blame everything on cliff. meanwhile abbey\\'s hateful spirit comes back for revenge and kills someone in cliff\\'s surrounding whenever she has a near fatal experience with the medical devices. after a few victims, cliff realizes it might be safer for him to keep his wife alive if he wants to remain alive as well. \"right to die\" is a stupendous episode and exactly the type of stuff i always hoped to see from a tv-series concept like \"masters of horror\". it\\'s violent and gory with a sick & twisted sense of humor and loads of sleaze sequences. the euthanasia theme and the whole obligatory media circus that surrounds it is processed into the script very well, yet without unnecessarily reverting to political standpoints or morality lessons. the atmosphere is suspenseful and the killing sequences are suitably nasty and unsettling. actresses julia anderson and robin sydney both have pretty face and impressively voluptuous racks, which is always a welcome plus, and corbin bernsen is finally offered the chance again to depict a mean-spirited and egocentric bastard. great \"moh\" episode; definitely one of the highlights of both seasons.',\n",
              "  1),\n",
              " (\"i wasn't sure whether to laugh or cry. porretta was good looking but resembled like a mexican porn star not an english outlaw. costumes? what costumes? a t-shirt with strips of black leather on it. it was marion's clothes--or lack of them--that really got me. do the 'fans' of this stinker really believe women dressed like that in medieval england. the mongols and vikings were inaccurate and stupid, but the episode with an alien was worst of all. especially as his make up mainly consisted of oatmeal on his face--an old trick.the hedgehog monster was pretty funny, as was climbing up the side of a castle on a ladder of arrows--as if. the us accents grated as did the initial drawling voice over' raw-bin hood and liddle john'.the second robin and marion were really quite minging in looks and what was left of the show went totally down the pan...\",\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "0V2GnN9Z6Yj4",
        "colab_type": "code",
        "outputId": "b374c199-4630-4ad4-fdca-b6fafa70b70f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9496d7f-b821-4141-a513-e1f751f1f7b5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d9496d7f-b821-4141-a513-e1f751f1f7b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-67ceb9457410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gwEQFKUT6cc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Test_5K.csv'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qs2rHjSN6k2b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.csv'].decode('utf-8')), sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTk26HxZ6qjj",
        "colab_type": "code",
        "outputId": "0ff1f371-75d5-42cb-e91a-0abfb73c2d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_test[df_test['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_test[df_test['label']==1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 2482\n",
            "Number of Positive movie reviews 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qirQBcpl60vS",
        "colab_type": "code",
        "outputId": "101ff2a3-5820-49b7-bbc3-c81e19300739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "text_reviews_test = df_test['text'].astype(str).tolist()\n",
        "text_labels_test = df_test['label'].astype(int)\n",
        "\n",
        "text_reviews_test = [x.lower() for x in text_reviews_test]\n",
        "print(text_reviews_test[0], text_labels_test[0])\n",
        "print(len(text_reviews_test), len(text_labels_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as always this is an inaccurate picture of the homeless. tv told a lot of lies about panhandlers in the early 1990s and made everyone look bad, and claimed we all made over $100 a day when $20-40 a day was much closer to reality. when someone drove by where i held up a sign offering to work, and offered me work, i actually went and took the work if i was physically able.and if i would been offered the $100,000 id damned sure invested in in apt prepaid for at least 2 years, and kept most in the bank and still left myself $10-20000 for nl $1-2 and $2-5 cash games at the casinos. i usually always win and could win decent if i just had a bankroll. instead i win about $1000 a month is all playing in always minimum buying in due to not wanting to risk losing it all. i was only homeless cause i didn't wanna risk spending all my money and going broke, sometimes i had over $1000-2000 in my sock while i slept outside. anyone wanting to talk contact sevencard2003 on yahoo messenger.i admit i was different than most homeless people though, due to the fact i never drank smoke or took drugs. im no longer homeless, am now in govt housing for $177 a month and getting ssi and spend most of my time winning at online poker. mom and sunflower diversified worked hard to get me ssi. glad my days of hiding in under the stage in the convention center of the casino at night sleeping, worrying about getting caught by security are finally over. had this tv crew picked me theyd been over a lot sooner. its a shame how they don't better select who they pick. 0\n",
            "5000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "89gIvwYSx_MJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "cb5f48c3-0864-42d5-ebd0-94beb8d7aa9b"
      },
      "cell_type": "code",
      "source": [
        "data_test = [(text_reviews_test[i], text_labels_test[i])for i in range(len(text_labels_test))]\n",
        "data_test[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"as always this is an inaccurate picture of the homeless. tv told a lot of lies about panhandlers in the early 1990s and made everyone look bad, and claimed we all made over $100 a day when $20-40 a day was much closer to reality. when someone drove by where i held up a sign offering to work, and offered me work, i actually went and took the work if i was physically able.and if i would been offered the $100,000 id damned sure invested in in apt prepaid for at least 2 years, and kept most in the bank and still left myself $10-20000 for nl $1-2 and $2-5 cash games at the casinos. i usually always win and could win decent if i just had a bankroll. instead i win about $1000 a month is all playing in always minimum buying in due to not wanting to risk losing it all. i was only homeless cause i didn't wanna risk spending all my money and going broke, sometimes i had over $1000-2000 in my sock while i slept outside. anyone wanting to talk contact sevencard2003 on yahoo messenger.i admit i was different than most homeless people though, due to the fact i never drank smoke or took drugs. im no longer homeless, am now in govt housing for $177 a month and getting ssi and spend most of my time winning at online poker. mom and sunflower diversified worked hard to get me ssi. glad my days of hiding in under the stage in the convention center of the casino at night sleeping, worrying about getting caught by security are finally over. had this tv crew picked me theyd been over a lot sooner. its a shame how they don't better select who they pick.\",\n",
              "  0),\n",
              " ('did the movie-makers even preview this before they released it? the script jumps from place to place without giving much explanation. the beginning doesn\\'t clarify if its a prequel or not. it starts with superman\\'s beginnings on earth and then jumps to a point after the last movie - but doesn\\'t really alert the viewer of this. very confusing! superman himself is weak and in need of prozac. he is portrayed as a potential home-wrecker, a stalker, and someone who is clearly depressed and confused. this type of character rarely makes for an interesting hero. the ending is absolutely ridiculous. superman ending up in a hospital just made me want to kill him off myself. i\\'m seriously waiting for a snl skit where superman appears on maury povich and maury says, \"the results are in - in the case of the child, superman, you are the father.\" to sum up - ok acting by this superman and kevin spacey, but horrible script. the movie is basically unwatchable.',\n",
              "  0),\n",
              " (\"heavily re-edited and often confusing, the original screen version of man on fire was at least ten years out of date when it was made and the passing years haven't made it any better. this is the kind of movie that producers with too much money and too little experience make to get attention and everyone else does just to pay off their outstanding alimony or their drug dealer, with scott glenn's bodyguard going out on a limb to rescue his 12-year-old charge, the kidnapped daughter of a wealthy italian family. an interesting cast - joe pesci, brooke adams, danny aiello, jonathan pryce - have all done better, the action is sluggish and sparse and only john scott's exceptionally fine score (part of which turned up in the last reel of die hard) makes a positive impression. one case where the remake (made by tony scott, the original choice of director for this version) is an improvement.\",\n",
              "  0),\n",
              " ('i notice that most of the people who think this film speaks the truth were either not born before the moon landings (1969-1972), or not old enough to appreciate them. i think it is much easier to question an historic event if you did not live through it.<br /><br />i was a youngster at the time of apollo, but i was old enough to understand what was going on. the entire world followed the moon landings. our families gathered around the tv to watch the launch. newspaper headlines screamed the latest goings-on each day, from launch to landing, from moonwalks to moon liftoff, all the way to splashdown, in a multitude of languages. in school, some classes were cancelled so we could watch the main events on tv. during apollo 13 the world prayed and held its collective breath as the men limped home to an uncertain fate. you couldn\\'t go anywhere without someone asking what the latest was. the world was truly one community. <br /><br />now with a buffer of 30-odd years after the fact, it is easy to claim fraud because worldwide enthusiasm and interest has died down. we are left with our history books, and anybody can claim that history is wrong and attempt to \"prove\" it with a bunch of lies and made-up facts while completely ignoring the preponderance of evidence showing otherwise--not to mention the proof that dwells in the souls and memories of those who lived through these wonderfully heady and fantastic days.',\n",
              "  0),\n",
              " ('first of all, this is a low-budget movie, so my expectations were incredibly low going into it. i assume most people looking at the info for this movie just wanted a bloodfest, and essentially that\\'s all it is.<br /><br />plot? there really is none. it\\'s basically saw but in china and a whole hell of a lot worse. cast? there is none, period. special effects? absolutely awful in my opinion... there were cutaways and the blood was often completely unbelievable because of amounts, splatter, color, texture, etc.<br /><br />i believe the purpose of this movie was supposed to be a brutal, shock film. now it had some great potential on a bigger budget but poor scripting, poor dialogue, awful acting, what seemed like camcorder video shots, and just plain unbelievable \"gore,\" made this movie truly awful.<br /><br />there are movies worth taking a chance against some reviews, even \"b-rate\" movies deserve some opportunities (blood trails for example was the most recent i saw against reviews that was worth it), but this was simply awful. i hope that people considering this movie read my comment and decide against it.<br /><br />i\\'m all for brutality and shock, but the overall unrealism and truly awful acting makes for an awful experience. save your time/money and chance something else, you won\\'t be disappointed.',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "zydP-RKS0GgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "COY4uTBU2OSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "    word_to_ix = {}\n",
        "    #print(dataset)\n",
        "    for sent in dataset:\n",
        "        for word in sent.split():\n",
        "            if word not in word_to_ix:\n",
        "                word_to_ix[word] = len(word_to_ix)\n",
        "    return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXGW8ypdRXsQ",
        "colab_type": "code",
        "outputId": "e030690b-4915-4f86-c26e-8e2cd0967d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = generate_word_ids(text_reviews + text_reviews_test)\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd_AuK5Xy679",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2BNlqrAJleH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task1"
      ]
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1A, self).__init__()\n",
        "        self.lin = nn.Linear(vocab_size, 50)\n",
        "\n",
        "    def forward(self, x): \n",
        "        return F.softmax(self.lin(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xu-8rq-AJj0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1B, self).__init__()\n",
        "        self.lin = nn.Linear(vocab_size, 100)\n",
        "\n",
        "    def forward(self, x): \n",
        "        return F.softmax(self.lin(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3EY8WlEKQKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1C, self).__init__()\n",
        "        self.lin = nn.Linear(vocab_size, 200)\n",
        "\n",
        "    def forward(self, x): \n",
        "        return F.softmax(self.lin(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44ZSyECsKSpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model1D, self).__init__()\n",
        "        self.lin = nn.Linear(vocab_size, 500)\n",
        "\n",
        "    def forward(self, x): \n",
        "        return F.softmax(self.lin(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aboTbOIuyVd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1A = Model1A(VOCAB_SIZE)\n",
        "model1B = Model1B(VOCAB_SIZE)\n",
        "model1C = Model1C(VOCAB_SIZE)\n",
        "model1D = Model1D(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJgvIuflzD7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "82a00a0d-6779-452e-9f2f-2d5893e061d4"
      },
      "cell_type": "code",
      "source": [
        "for param in model1B.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.5323e-03, -1.0307e-03, -1.1661e-03,  ...,  1.7003e-03,\n",
            "          1.7095e-03,  1.9406e-03],\n",
            "        [ 8.7161e-04, -1.4548e-04,  1.7824e-03,  ..., -1.1318e-03,\n",
            "          1.3659e-03,  6.6149e-04],\n",
            "        [-2.0809e-04, -1.8245e-03, -1.0402e-03,  ..., -8.5727e-04,\n",
            "         -3.1714e-04, -4.2096e-05],\n",
            "        ...,\n",
            "        [-1.8415e-03, -1.1643e-04, -1.7634e-03,  ..., -8.3554e-04,\n",
            "          9.2890e-04,  1.2310e-03],\n",
            "        [ 7.6921e-04, -2.0000e-03,  2.9621e-04,  ..., -6.2388e-04,\n",
            "          4.0928e-04, -1.4617e-03],\n",
            "        [-3.3858e-04, -8.1623e-06, -1.8346e-03,  ...,  1.0451e-03,\n",
            "         -1.9498e-03, -1.6412e-03]], requires_grad=True) torch.Size([100, 239036])\n",
            "Parameter containing:\n",
            "tensor([ 1.7947e-03,  1.4776e-03, -1.9472e-03, -8.3788e-04, -1.7675e-04,\n",
            "         3.1254e-04, -1.0194e-03,  3.2568e-04,  1.1669e-03, -1.0724e-03,\n",
            "         8.7806e-04,  1.6165e-03,  8.6477e-04, -9.7027e-04,  1.8422e-03,\n",
            "         1.9133e-03, -1.8741e-03,  1.6015e-03, -1.9529e-03,  8.5281e-04,\n",
            "        -8.4508e-04, -1.8678e-03, -1.3086e-03, -4.5419e-04, -9.9760e-04,\n",
            "        -1.5761e-03, -1.9593e-03,  8.5706e-04, -6.6667e-04,  1.0455e-03,\n",
            "         2.8505e-04,  5.4131e-04,  1.9209e-03, -9.1655e-04, -9.6040e-04,\n",
            "         1.9881e-03, -1.8539e-03,  5.3849e-04, -7.2585e-04, -1.2481e-03,\n",
            "         2.4930e-04, -2.0311e-03, -1.7446e-03,  8.4981e-04, -1.0333e-03,\n",
            "        -1.7047e-03,  1.3885e-04,  1.2677e-03, -1.4453e-03, -1.1493e-03,\n",
            "         2.5172e-04,  1.4776e-03, -1.8678e-03, -1.2068e-03,  3.0314e-04,\n",
            "        -3.4508e-04,  2.0922e-04,  1.8635e-03,  3.8447e-04, -1.5428e-03,\n",
            "        -2.0254e-03, -7.3087e-04,  1.2767e-03, -7.8155e-04,  3.4957e-04,\n",
            "        -1.8288e-03, -1.4396e-03, -1.3044e-03,  4.5494e-05, -1.5375e-03,\n",
            "         1.3664e-03,  4.9555e-04, -1.1693e-03,  5.7965e-05, -6.5161e-04,\n",
            "        -7.4273e-04,  7.3486e-04, -8.6421e-04,  1.0459e-03,  1.8347e-03,\n",
            "        -2.0809e-04,  1.2383e-03,  1.6884e-03,  1.8696e-03, -1.0674e-03,\n",
            "        -7.9785e-05,  1.0799e-03,  2.3294e-04, -1.9005e-03,  1.8093e-03,\n",
            "        -2.2919e-04, -3.3330e-05,  1.6979e-03, -1.7047e-03,  1.3585e-03,\n",
            "         1.5257e-03,  1.1916e-03, -8.5871e-04, -1.7075e-03,  1.9866e-03],\n",
            "       requires_grad=True) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eXZ5oiJz3oRs"
      },
      "cell_type": "markdown",
      "source": [
        "##Task2"
      ]
    },
    {
      "metadata": {
        "id": "AC5vnfLG3s8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 10)\n",
        "        self.lin2 = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAl-p3ST3svP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 20)\n",
        "        self.lin2 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gI_C_AC3srz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 30)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xeu29fbI3sjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 50)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWWVSG8z4rnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2E(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model2E, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gcyPaqzo42Ea"
      },
      "cell_type": "markdown",
      "source": [
        "##Task3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kire3o2W42Ed",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model3A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        x = F.softmax(self.lin2(x))\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hPQL-96z42Eq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model3B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model3B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 100)\n",
        "        self.lin3 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        x = F.softmax(self.lin2(x))\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pGje3Qmb53SB"
      },
      "cell_type": "markdown",
      "source": [
        "##Task4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1q9dRGoH53SF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=p)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        x = F.softmax(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Cxk52Poe53SN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=p)\n",
        "        self.lin2 = nn.Linear(100, 100)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        x = self.drop_layer(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7f8iUrh6K5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model4C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model4C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=p)\n",
        "        self.lin2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.softmax(self.lin1(x))\n",
        "        x = self.drop_layer(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_P3kpbn6CkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task5"
      ]
    },
    {
      "metadata": {
        "id": "WyuNEDLy6F-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=p)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jvAMDPl6IDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model5B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Model5B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=p)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.t(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdBYZH5C6H-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9q06ioWi6H4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUigOUZZ6Hwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMIoCKTv2oJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run code"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SWNifAEh42FG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.NLLLoss()\n",
        "opt = torch.optim.SGD(model1A.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7wPIJAKM42FL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "    tic = time.time()\n",
        "    # the training loop\n",
        "    for epoch in range(10):\n",
        "        for instance, label in data:\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "            label = make_target(label)\n",
        "            probs = model(bow_vec) # forward pass\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN'.format(epoch, loss.data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "--MMxg1r42FR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(model1A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d416cd05-0a17-42da-ebd1-6eb3f96b86b9",
        "id": "ovWIpc5K42Ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "for instance, label in data_test:\n",
        "    bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "    logprobs = bow(bow_vec)\n",
        "    print(logprobs)\n",
        "    pred = np.argmax(logprobs.data.numpy())\n",
        "    print('prediction: {}'.format(ix_to_label[pred]))\n",
        "    print('actual: {}'.format(label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c9dc331da8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- AFTER TRAINING ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbow_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_bow_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d2837bcb3c35>\u001b[0m in \u001b[0;36mmake_bow_vector\u001b[0;34m(sentence, word_to_ix)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' not present in the dictionary. Sorry!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Word', 'panhandlers', ' not present in the dictionary. Sorry!')"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nWwPM8BG3_HW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.NLLLoss()\n",
        "opt = torch.optim.SGD(model1A.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MqpTr0l01rId",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "    tic = time.time()\n",
        "    # the training loop\n",
        "    for epoch in range(10):\n",
        "        for instance, label in data:\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "            label = make_target(label)\n",
        "            probs = model(bow_vec) # forward pass\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN'.format(epoch, loss.data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSsNKoiA7gf5",
        "colab_type": "code",
        "outputId": "ec317928-2425-47e5-d00c-4a4c0bd69b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "train(model1A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: -3385.6826171875, TIME TAKEN\n",
            "EPOCH: 1, CURRENT LOSS: -5143.83984375, TIME TAKEN\n",
            "EPOCH: 2, CURRENT LOSS: -6902.068359375, TIME TAKEN\n",
            "EPOCH: 3, CURRENT LOSS: -8660.3623046875, TIME TAKEN\n",
            "EPOCH: 4, CURRENT LOSS: -10418.7958984375, TIME TAKEN\n",
            "EPOCH: 5, CURRENT LOSS: -12177.2568359375, TIME TAKEN\n",
            "EPOCH: 6, CURRENT LOSS: -13935.744140625, TIME TAKEN\n",
            "EPOCH: 7, CURRENT LOSS: -15694.2529296875, TIME TAKEN\n",
            "EPOCH: 8, CURRENT LOSS: -17452.837890625, TIME TAKEN\n",
            "EPOCH: 9, CURRENT LOSS: -19211.40625, TIME TAKEN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uH4FBsR-36xh",
        "colab_type": "code",
        "outputId": "d416cd05-0a17-42da-ebd1-6eb3f96b86b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "for instance, label in data_test:\n",
        "    bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "    logprobs = bow(bow_vec)\n",
        "    print(logprobs)\n",
        "    pred = np.argmax(logprobs.data.numpy())\n",
        "    print('prediction: {}'.format(ix_to_label[pred]))\n",
        "    print('actual: {}'.format(label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c9dc331da8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- AFTER TRAINING ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbow_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_bow_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d2837bcb3c35>\u001b[0m in \u001b[0;36mmake_bow_vector\u001b[0;34m(sentence, word_to_ix)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' not present in the dictionary. Sorry!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Word', 'panhandlers', ' not present in the dictionary. Sorry!')"
          ]
        }
      ]
    }
  ]
}