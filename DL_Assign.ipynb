{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirius-Aabhas/CS69002_9A_18CS60R55/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bRuGSGqnMOXz",
        "colab_type": "code",
        "outputId": "3d9c66e4-ad63-49ec-e8b7-d9a3f05c8dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "device = torch.device('cuda:0')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "ijrEth3MRQ6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Fetching data"
      ]
    },
    {
      "metadata": {
        "id": "J5ITVAYmiy5H",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "86de166e-dc33-4b30-98be-262b5b1a8073"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c982c8a7-b5bd-42b3-8ccb-1d7e98d811e1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c982c8a7-b5bd-42b3-8ccb-1d7e98d811e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Train_20K.csv to Train_20K (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQLFDGIQjrh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b55dadf1-fe16-4cb0-dbac-264dd1739b7c"
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Train_20K.csv'])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, dict_keys(['Train_20K.csv']), bytes)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "o7sqK9HKoGzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9422a0bc-4d40-41db-8ee7-0e2d8f960a1d"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Waters has given us a genuinely enjoyable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This first two seasons of this comedy series w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What an unfortunate mess is \"Shiner.\" I wanted...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm not entirely sure Rob Schmidt qualifies as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i wasn't sure whether to laugh or cry. Porrett...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  John Waters has given us a genuinely enjoyable...      1\n",
              "1  This first two seasons of this comedy series w...      1\n",
              "2  What an unfortunate mess is \"Shiner.\" I wanted...      0\n",
              "3  I'm not entirely sure Rob Schmidt qualifies as...      1\n",
              "4  i wasn't sure whether to laugh or cry. Porrett...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "zvXSxRtMNw8U",
        "colab_type": "code",
        "outputId": "8ad61a50-52ca-48ec-c73b-ad81dbf0fa05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df[df['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df[df['label']==1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rbQhm8mQ7BN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b94aad0a-36f9-43fd-a729-5aec630c21e2"
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "\n",
        "filtered_text_reviews = []\n",
        "for sent in text_reviews:\n",
        "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
        "    word_tokens = word_tokenize(sent)\n",
        "    filtered_text_reviews.append(' '.join([w for w in word_tokens if (not w in stop_words and w != 'br')]))\n",
        "            \n",
        "text_reviews = filtered_text_reviews\n",
        "print(text_reviews[0], text_labels[0])\n",
        "print(len(text_reviews), len(text_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "john waters given us genuinely enjoyable film certainly isnt without shocking watersesque moments tamer older culty stuff pink flamingoes pecker harkens back johns early mainstream stage reminds viewer kind humor evident polyester overall really fun comedy great moments 1\n",
            "17999 17999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tOgBzlyA2znw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "cd9c7e91-2a66-418b-dc3f-74bc4111c459"
      },
      "cell_type": "code",
      "source": [
        "data = [(text_reviews[i], text_labels[i])for i in range(len(text_labels))]\n",
        "data[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('john waters given us genuinely enjoyable film certainly isnt without shocking watersesque moments tamer older culty stuff pink flamingoes pecker harkens back johns early mainstream stage reminds viewer kind humor evident polyester overall really fun comedy great moments',\n",
              "  1),\n",
              " ('first two seasons comedy series strange werent funny drama element bill mother struggling usual problems life element bit depressing didnt mix well th comedy elements probably dropped soon became one funniest comedy series bbc ever made chemistry bill bens characters funny always many brilliant memorable sketches series christmas specials hilarious real treat christmas show came stop main actor gary olsen playing bill passed away sad brilliant actor films n funny man ripbr underrated show sadly disappeared television screens doesnt repeated often though appear uktv gold repeated bbc one two show brilliant comedy new audience',\n",
              "  1),\n",
              " ('unfortunate mess shiner wanted like overthetop antifilm aspirant fact found number moments powerful resonance sadly moments far appreciate calson attempting advantage aspired bare bones budget cinematography destroyed truly atrocious editing benefited movie allbr bad acting abounds low budget big budget cinema shiner remarkably bad performances nearly painful watch particular straight couple linda young guy two poorly written characters offering almost nothing story acting abysmal neither actor seems capable resisting smirking cracking drearily drop lines appalling lack skill choppy editing almost lends feeling roles entirely gratuitous dropped avoid films stereotypically cast oddball gay film would better suchbr going wrong several performances seem capture calson hoping get particular story centering bob tim two richly drawn characters offer rewards genuinely captivating performances nicholas king bob david zelinas tim tim boxer serious issues remarkably low self esteem disguised almost cartoon like arrogance wears like armour plating obsessed tim seemingly harmless yet ultimately creepy bob stalks boxer classic catandmouse fashion tables turned hunter becomes hunted resulting films genuine emotional catharsis film artificially hardedged thats compliment one character must revelatory break breakdown case proves final confrontation bob tim provide zelinas king opportunity display real acting chopsbr played scott stepp derris nile tony danny seem focus movie despite bravado moments including one truly disturbing scene revealing sexviolence obsession cant seem escape cartoonlike artifice difficult look beyond seeming one note symphony find anything obviousbr ultimately raw material could used tell story better fashion alas really isnt much recommend yet performances messrs king zelinas really offer something special glimpse might ultimately worth seeing',\n",
              "  0),\n",
              " ('im entirely sure rob schmidt qualifies master genre horror since previously directed one horror film called wrong turn one actually slightly mediocre fact made right die one best creepiest episodes entire second season masters horror franchise similar underdog story season one william malone made best episodes fair haired child even though long feature films fear dot com house haunted hill sucked pretty badlybr story right die cleverly picks nowadays piping hot social debate euthanasia thankfully also features multiple oldfashioned horror themes like ghostly vengeance murderous conspiracies pitch black humor comic book styled violence whilst driving home late one night discussing husbands continuous adultery addison couple involved terrible car accident cliff walks away wreck unharmed wife abby fully burned needs kept alive artificially whilst cliff sleazy attorney corbin bernsen dentist want plug plug sue car constructor abbeys mum sets giant media campaign keep daughter alive vegetable blame everything cliff meanwhile abbeys hateful spirit comes back revenge kills someone cliffs surrounding whenever near fatal experience medical devices victims cliff realizes might safer keep wife alive wants remain alive well right die stupendous episode exactly type stuff always hoped see tvseries concept like masters horror violent gory sick twisted sense humor loads sleaze sequences euthanasia theme whole obligatory media circus surrounds processed script well yet without unnecessarily reverting political standpoints morality lessons atmosphere suspenseful killing sequences suitably nasty unsettling actresses julia anderson robin sydney pretty face impressively voluptuous racks always welcome plus corbin bernsen finally offered chance depict meanspirited egocentric bastard great moh episode definitely one highlights seasons',\n",
              "  1),\n",
              " ('wasnt sure whether laugh cry porretta good looking resembled like mexican porn star english outlaw costumes costumes tshirt strips black leather marions clothesor lack themthat really got fans stinker really believe women dressed like medieval england mongols vikings inaccurate stupid episode alien worst especially make mainly consisted oatmeal facean old trickthe hedgehog monster pretty funny climbing side castle ladder arrowsas us accents grated initial drawling voice rawbin hood liddle johnthe second robin marion really quite minging looks left show went totally pan',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "0V2GnN9Z6Yj4",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d41849a1-fbb0-4e48-89e2-52292528a368"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79bcd490-e5f6-47d8-abfc-73e6e17334a4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-79bcd490-e5f6-47d8-abfc-73e6e17334a4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Test_5K.csv to Test_5K (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gwEQFKUT6cc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "325660d9-6e5d-4b6b-83af-f6ad60bf7c9a"
      },
      "cell_type": "code",
      "source": [
        "type(uploaded), uploaded.keys(), type(uploaded['Test_5K.csv'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, dict_keys(['Test_5K.csv']), bytes)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Qs2rHjSN6k2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5469c335-ecaa-4372-9fe8-11cbba73ddae"
      },
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.csv'].decode('utf-8')), sep='\\t')\n",
        "df_test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>as always this is an inaccurate picture of the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did the movie-makers even preview this before ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Heavily re-edited and often confusing, the ori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I notice that most of the people who think thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>First of all, this is a low-budget movie, so m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  as always this is an inaccurate picture of the...      0\n",
              "1  Did the movie-makers even preview this before ...      0\n",
              "2  Heavily re-edited and often confusing, the ori...      0\n",
              "3  I notice that most of the people who think thi...      0\n",
              "4  First of all, this is a low-budget movie, so m...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "LTk26HxZ6qjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "337cbb50-2f67-4747-cb76-e8396058fb20"
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_test[df_test['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_test[df_test['label']==1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 2482\n",
            "Number of Positive movie reviews 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qirQBcpl60vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2effd4d2-44eb-4d4b-e068-7bc160e708b9"
      },
      "cell_type": "code",
      "source": [
        "text_reviews_test = df_test['text'].astype(str).tolist()\n",
        "text_labels_test = df_test['label'].astype(int)\n",
        "\n",
        "text_reviews_test = [x.lower() for x in text_reviews_test]\n",
        "\n",
        "filtered_text_reviews = []\n",
        "for sent in text_reviews_test:\n",
        "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
        "    word_tokens = word_tokenize(sent)\n",
        "    filtered_text_reviews.append(' '.join([w for w in word_tokens if (not w in stop_words and w != 'br')]))\n",
        "            \n",
        "text_reviews_test = filtered_text_reviews\n",
        "\n",
        "print(text_reviews_test[0], text_labels_test[0])\n",
        "print(len(text_reviews_test), len(text_labels_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "always inaccurate picture homeless tv told lot lies panhandlers early 1990s made everyone look bad claimed made 100 day 2040 day much closer reality someone drove held sign offering work offered work actually went took work physically ableand would offered 100000 id damned sure invested apt prepaid least 2 years kept bank still left 1020000 nl 12 25 cash games casinos usually always win could win decent bankroll instead win 1000 month playing always minimum buying due wanting risk losing homeless cause didnt wan na risk spending money going broke sometimes 10002000 sock slept outside anyone wanting talk contact sevencard2003 yahoo messengeri admit different homeless people though due fact never drank smoke took drugs im longer homeless govt housing 177 month getting ssi spend time winning online poker mom sunflower diversified worked hard get ssi glad days hiding stage convention center casino night sleeping worrying getting caught security finally tv crew picked theyd lot sooner shame dont better select pick 0\n",
            "5000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "89gIvwYSx_MJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "56f5e912-f32f-4abd-af9b-f33dc61473bf"
      },
      "cell_type": "code",
      "source": [
        "data_test = [(text_reviews_test[i], text_labels_test[i])for i in range(len(text_labels_test))]\n",
        "data_test[:5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('always inaccurate picture homeless tv told lot lies panhandlers early 1990s made everyone look bad claimed made 100 day 2040 day much closer reality someone drove held sign offering work offered work actually went took work physically ableand would offered 100000 id damned sure invested apt prepaid least 2 years kept bank still left 1020000 nl 12 25 cash games casinos usually always win could win decent bankroll instead win 1000 month playing always minimum buying due wanting risk losing homeless cause didnt wan na risk spending money going broke sometimes 10002000 sock slept outside anyone wanting talk contact sevencard2003 yahoo messengeri admit different homeless people though due fact never drank smoke took drugs im longer homeless govt housing 177 month getting ssi spend time winning online poker mom sunflower diversified worked hard get ssi glad days hiding stage convention center casino night sleeping worrying getting caught security finally tv crew picked theyd lot sooner shame dont better select pick',\n",
              "  0),\n",
              " ('moviemakers even preview released script jumps place place without giving much explanation beginning doesnt clarify prequel starts supermans beginnings earth jumps point last movie doesnt really alert viewer confusing superman weak need prozac portrayed potential homewrecker stalker someone clearly depressed confused type character rarely makes interesting hero ending absolutely ridiculous superman ending hospital made want kill im seriously waiting snl skit superman appears maury povich maury says results case child superman father sum ok acting superman kevin spacey horrible script movie basically unwatchable',\n",
              "  0),\n",
              " ('heavily reedited often confusing original screen version man fire least ten years date made passing years havent made better kind movie producers much money little experience make get attention everyone else pay outstanding alimony drug dealer scott glenns bodyguard going limb rescue 12yearold charge kidnapped daughter wealthy italian family interesting cast joe pesci brooke adams danny aiello jonathan pryce done better action sluggish sparse john scotts exceptionally fine score part turned last reel die hard makes positive impression one case remake made tony scott original choice director version improvement',\n",
              "  0),\n",
              " ('notice people think film speaks truth either born moon landings 19691972 old enough appreciate think much easier question historic event live itbr youngster time apollo old enough understand going entire world followed moon landings families gathered around tv watch launch newspaper headlines screamed latest goingson day launch landing moonwalks moon liftoff way splashdown multitude languages school classes cancelled could watch main events tv apollo 13 world prayed held collective breath men limped home uncertain fate couldnt go anywhere without someone asking latest world truly one community buffer 30odd years fact easy claim fraud worldwide enthusiasm interest died left history books anybody claim history wrong attempt prove bunch lies madeup facts completely ignoring preponderance evidence showing otherwisenot mention proof dwells souls memories lived wonderfully heady fantastic days',\n",
              "  0),\n",
              " ('first lowbudget movie expectations incredibly low going assume people looking info movie wanted bloodfest essentially thats isbr plot really none basically saw china whole hell lot worse cast none period special effects absolutely awful opinion cutaways blood often completely unbelievable amounts splatter color texture etcbr believe purpose movie supposed brutal shock film great potential bigger budget poor scripting poor dialogue awful acting seemed like camcorder video shots plain unbelievable gore made movie truly awfulbr movies worth taking chance reviews even brate movies deserve opportunities blood trails example recent saw reviews worth simply awful hope people considering movie read comment decide itbr im brutality shock overall unrealism truly awful acting makes awful experience save timemoney chance something else wont disappointed',\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "zydP-RKS0GgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "COY4uTBU2OSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "    word_to_ix = {}\n",
        "    word_cntr = {}\n",
        "    word_set = set()\n",
        "    #print(dataset)\n",
        "    for sent in dataset:\n",
        "        for word in sent.split():\n",
        "            if word not in word_cntr:\n",
        "                word_cntr[word] = 1\n",
        "            else:\n",
        "                word_cntr[word] += 1\n",
        "    \n",
        "    for word in word_cntr:\n",
        "        if word_cntr[word] >= 5:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "            \n",
        "    word_to_ix['<UNKNOWN>'] = len(word_to_ix)\n",
        "        \n",
        "    return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXGW8ypdRXsQ",
        "colab_type": "code",
        "outputId": "7f29f919-76d2-43c3-c316-c1bd7aaa611c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = generate_word_ids(text_reviews + text_reviews_test)\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd_AuK5Xy679",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['<UNKNOWN>']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n7XiuOLoWQlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "a19f1eb8-4eb1-47eb-aa70-f09fa7fc437e"
      },
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "features = make_bow_vector(text_reviews[0], word_to_ix).to(device)\n",
        "for i in range(1,len(text_reviews)):\n",
        "    vec = make_bow_vector(text_reviews[i], word_to_ix).to(device)\n",
        "    features = torch.cat((features,vec)).to(device)\n",
        "    if i%1000 == 0:\n",
        "        print(time.time() - t1)\n",
        "        t1 = time.time()\n",
        "        print(features.shape)\n",
        "targets = torch.tensor(text_labels, dtype=torch.int).to(device)\n",
        "\n",
        "print(time.time() - t1)\n",
        "print(features.shape)\n",
        "print(targets.shape)\n",
        "train = data_utils.TensorDataset(features, targets)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=32, shuffle=True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1611812114715576\n",
            "torch.Size([1001, 30624])\n",
            "3.379796266555786\n",
            "torch.Size([2001, 30624])\n",
            "5.205514192581177\n",
            "torch.Size([3001, 30624])\n",
            "7.2094032764434814\n",
            "torch.Size([4001, 30624])\n",
            "9.266945838928223\n",
            "torch.Size([5001, 30624])\n",
            "11.305914163589478\n",
            "torch.Size([6001, 30624])\n",
            "13.67388653755188\n",
            "torch.Size([7001, 30624])\n",
            "15.828752517700195\n",
            "torch.Size([8001, 30624])\n",
            "17.930289030075073\n",
            "torch.Size([9001, 30624])\n",
            "20.040346145629883\n",
            "torch.Size([10001, 30624])\n",
            "22.143686056137085\n",
            "torch.Size([11001, 30624])\n",
            "24.16520047187805\n",
            "torch.Size([12001, 30624])\n",
            "121.0351734161377\n",
            "torch.Size([13001, 30624])\n",
            "170.08469438552856\n",
            "torch.Size([14001, 30624])\n",
            "181.17917203903198\n",
            "torch.Size([15001, 30624])\n",
            "193.8370544910431\n",
            "torch.Size([16001, 30624])\n",
            "208.7408492565155\n",
            "torch.Size([17001, 30624])\n",
            "220.95192861557007\n",
            "torch.Size([17999, 30624])\n",
            "torch.Size([17999])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "br8deJ3RsNP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d49d6d49-f25a-4483-cea7-81d9a66d3624"
      },
      "cell_type": "code",
      "source": [
        "features[0].shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30624])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "B2BNlqrAJleH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task1"
      ]
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task1A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task1A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xu-8rq-AJj0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task1B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task1B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3EY8WlEKQKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task1C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task1C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44ZSyECsKSpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task1D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task1D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 500)\n",
        "        self.lin2 = nn.Linear(500, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        return F.softmax(self.lin2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aboTbOIuyVd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1A = Task1A(VOCAB_SIZE)\n",
        "model1B = Task1B(VOCAB_SIZE)\n",
        "model1C = Task1C(VOCAB_SIZE)\n",
        "model1D = Task1D(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJgvIuflzD7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model1A.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eXZ5oiJz3oRs"
      },
      "cell_type": "markdown",
      "source": [
        "##Task2"
      ]
    },
    {
      "metadata": {
        "id": "AC5vnfLG3s8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task2A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 10)\n",
        "        self.lin2 = nn.Linear(10, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAl-p3ST3svP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task2B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 20)\n",
        "        self.lin2 = nn.Linear(20, 10)\n",
        "        self.lin3 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gI_C_AC3srz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task2C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 30)\n",
        "        self.lin3 = nn.Linear(30, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xeu29fbI3sjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2D(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task2D, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 50)\n",
        "        self.lin2 = nn.Linear(50, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWWVSG8z4rnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task2E(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task2E, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "y_MUqcWjpbBA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2A = Task2A(VOCAB_SIZE)\n",
        "model2B = Task2B(VOCAB_SIZE)\n",
        "model2C = Task2C(VOCAB_SIZE)\n",
        "model2D = Task2D(VOCAB_SIZE)\n",
        "model2E = Task2E(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gcyPaqzo42Ea"
      },
      "cell_type": "markdown",
      "source": [
        "##Task3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Kire3o2W42Ed",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task3A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task3A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.lin2 = nn.Linear(100, 50)\n",
        "        self.lin3 = nn.Linear(50, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hPQL-96z42Eq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task3B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task3B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 200)\n",
        "        self.lin2 = nn.Linear(200, 100)\n",
        "        self.lin3 = nn.Linear(100, 10)\n",
        "        self.lin4 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6HYfG8pv2Wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3A = Task3A(VOCAB_SIZE)\n",
        "model3B = Task3B(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pGje3Qmb53SB"
      },
      "cell_type": "markdown",
      "source": [
        "##Task4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1q9dRGoH53SF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task4A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task4A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Cxk52Poe53SN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task4B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task4B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 100)\n",
        "        self.lin3 = nn.Linear(100,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7f8iUrh6K5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task4C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task4C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 100)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin2 = nn.Linear(100, 10)\n",
        "        self.lin3 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.softmax(self.lin3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UR_5Ny8Lc11s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model4A = Task4A(VOCAB_SIZE)\n",
        "model4B = Task4B(VOCAB_SIZE)\n",
        "model4C = Task4C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_P3kpbn6CkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task5"
      ]
    },
    {
      "metadata": {
        "id": "WyuNEDLy6F-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task5A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task5A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jvAMDPl6IDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task5B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task5B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.tanh(self.lin1(x))\n",
        "        x = F.tanh(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.tanh(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdBYZH5C6H-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task5C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task5C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.sigmoid(self.lin1(x))\n",
        "        x = F.sigmoid(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.sigmoid(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9q06ioWi6H4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model5A = Task5A(VOCAB_SIZE)\n",
        "model5B = Task5B(VOCAB_SIZE)\n",
        "model5C = Task5C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUigOUZZ6Hwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model5A.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XxKqNECsxCSU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task7"
      ]
    },
    {
      "metadata": {
        "id": "SzM0aA9fxIwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task7A(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task7A, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwlQU15XxP82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task7B(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task7B, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUzY81cYxSbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task7C(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task7C, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nV9Io_wkxYKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model7A = Task7A(VOCAB_SIZE)\n",
        "model7B = Task7B(VOCAB_SIZE)\n",
        "model7C = Task7C(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMIoCKTv2oJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train, validate, save"
      ]
    },
    {
      "metadata": {
        "id": "-laO3EGUUjNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_one_hot(labels):\n",
        "    ret_list = torch.zeros((len(labels), 2))\n",
        "    for i, label in enumerate(labels):\n",
        "        ret_list[i][label] = 1\n",
        "    return ret_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8yGFyUV-ykT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, isGpu):\n",
        "    if isGpu:\n",
        "        model = model.to(device)\n",
        "    # define a loss function and an optimizer\n",
        "    #loss_function = nn.NLLLoss()\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "    # the training loop\n",
        "    for epoch in range(30):\n",
        "        tic = time.time()\n",
        "        for batch_idx, (instance, label) in enumerate(train_loader):\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            label = label.long()\n",
        "            probs = model(instance) # forward pass\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDByWSZOPt7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_MSE_Hinge(model, isGpu, loss_function):\n",
        "    if isGpu:\n",
        "        model = model.to(device)\n",
        "        \n",
        "    opt = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "    # the training loop\n",
        "    for epoch in range(30):\n",
        "        tic = time.time()\n",
        "        for batch_idx, (instance, label) in enumerate(train_loader):\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            label = label.long()\n",
        "            probs = model(instance) # forward pass\n",
        "            label = make_one_hot(label).to(device)\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovWIpc5K42Ff",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(model):\n",
        "    model = model.cpu()\n",
        "    preds = []\n",
        "    for instance, label in data_test:\n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "        logprobs = model(bow_vec)\n",
        "        #print(logprobs)\n",
        "        pred = np.argmax(logprobs.data.cpu().numpy())\n",
        "        preds.append(pred)\n",
        "\n",
        "    print('accuracy: {}'.format(accuracy_score(text_labels_test, preds)))\n",
        "    print('precision: {}'.format(precision_score(text_labels_test, preds)))\n",
        "    print('recall: {}'.format(recall_score(text_labels_test, preds)))\n",
        "    print('f1-score: {}'.format(f1_score(text_labels_test, preds)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "--MMxg1r42FR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_and_save(model): \n",
        "    train(model, True)\n",
        "    validate(model)\n",
        "    torch.save(model, model._get_name()+'.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acUKLyI3gvpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_and_save(model1B)\n",
        "run_and_save(model1C)\n",
        "run_and_save(model1D)\n",
        "run_and_save(model2A)\n",
        "run_and_save(model2B)\n",
        "run_and_save(model2C)\n",
        "run_and_save(model2D)\n",
        "run_and_save(model2E)\n",
        "run_and_save(model3A)\n",
        "run_and_save(model3B)\n",
        "run_and_save(model4A)\n",
        "run_and_save(model4B)\n",
        "run_and_save(model4C)\n",
        "run_and_save(model5A)\n",
        "run_and_save(model5B)\n",
        "run_and_save(model5C)\n",
        "run_and_save(model7A)\n",
        "train_MSE_Hinge(model7B, True, nn.MSELoss())\n",
        "validate(model7B)\n",
        "torch.save(model7B, 'Task7B.mdl')\n",
        "train_MSE_Hinge(model7C, True, nn.HingeEmbeddingLoss())\n",
        "validate(model7C)\n",
        "torch.save(model7C, 'Task7C.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDP0j9klAf9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdl_1a = torch.load('Task7B.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0ZU0noHFDSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validate(mdl_1a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkxsWrJBAGte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task6\n"
      ]
    },
    {
      "metadata": {
        "id": "ZA2dwDSsQy6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Bigram generation"
      ]
    },
    {
      "metadata": {
        "id": "VMjHuF-kAJ0j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bigrm_list = []\n",
        "for text in text_reviews+text_reviews_test:\n",
        "    words = text.split()\n",
        "    bigrm_list += (b for b in zip(words[:-1], words[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgcW2x5wA48j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bigrm_cntr = {}\n",
        "bigrm_to_ix = {}\n",
        "for bigrm in bigrm_list:\n",
        "    if bigrm not in bigrm_cntr:\n",
        "        bigrm_cntr[bigrm] = 1\n",
        "    else:\n",
        "        bigrm_cntr[bigrm] += 1\n",
        "\n",
        "for bigrm in bigrm_cntr:\n",
        "    if bigrm_cntr[bigrm] >= 5:\n",
        "        bigrm_to_ix[bigrm] = len(bigrm_to_ix)\n",
        "        \n",
        "bigrm_to_ix['<UNKNOWN>'] = len(bigrm_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l4vO83-tBrNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb4aacd-c53b-449c-d261-f0db6e0362e7"
      },
      "cell_type": "code",
      "source": [
        "BIGRAM_VOCAB_SIZE = len(bigrm_to_ix)\n",
        "BIGRAM_VOCAB_SIZE"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "9ayq9EvXQ3Y-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model"
      ]
    },
    {
      "metadata": {
        "id": "QfPmK-JmDW_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task6(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task6, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.3)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "model6 = Task6(BIGRAM_VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M96hXeshQ5KR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Trainig, validation and save"
      ]
    },
    {
      "metadata": {
        "id": "t7P-a6iyrKHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bigrm_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in zip(sentence.split()[:-1], words[1:]):\n",
        "        if word not in word_to_ix:\n",
        "            #raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            vec[word_to_ix['<UNKNOWN>']]+=1\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h01W3Y3ZCy2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e77d12b9-273f-48e7-a30c-b00fa9ae4191"
      },
      "cell_type": "code",
      "source": [
        "model6 = model6.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(model6.parameters(), lr = 0.5)\n",
        "for epoch in range(1):\n",
        "    tic = time.time()\n",
        "    for instance, label in data:\n",
        "        model6.zero_grad()\n",
        "        vec = Variable(make_bigrm_bow_vector(instance, bigrm_to_ix)).to(device)\n",
        "        label = Variable(make_target(label)).to(device)\n",
        "        probs = model6(vec) # forward pass\n",
        "        loss = loss_function(probs, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    toc = time.time()\n",
        "    print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.31326162815093994, TIME TAKEN: 54.89679265022278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EmhaIZOG96A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "45d94efa-8cd4-4bc0-8cfe-d4d9694bbb36"
      },
      "cell_type": "code",
      "source": [
        "model6 = model6.cpu()\n",
        "preds = []\n",
        "for instance, label in data_test:\n",
        "    bow_vec = Variable(make_bigrm_bow_vector(instance, bigrm_to_ix))\n",
        "    logprobs = model6(bow_vec)\n",
        "    #print(logprobs)\n",
        "    pred = np.argmax(logprobs.data.cpu().numpy())\n",
        "    preds.append(pred)\n",
        "\n",
        "print('accuracy: {}'.format(accuracy_score(text_labels_test, preds)))\n",
        "print('precision: {}'.format(precision_score(text_labels_test, preds)))\n",
        "print('recall: {}'.format(recall_score(text_labels_test, preds)))\n",
        "print('f1-score: {}'.format(f1_score(text_labels_test, preds)))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.4964\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f1-score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0_zEEsweIh8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6d3a9870-7e6c-470f-d474-92938f7ab6b8"
      },
      "cell_type": "code",
      "source": [
        "torch.save(model6, 'Task6.mdl')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task6. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1JqRyGhMmrN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('bigram_dictionary.pkl', 'wb') as f:\n",
        "    pickle.dump(bigrm_to_ix, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRe0WCW4mCuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task8"
      ]
    },
    {
      "metadata": {
        "id": "h5ENyeBomFWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Task8(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Task8, self).__init__()\n",
        "        self.lin1 = nn.Linear(vocab_size, 30)\n",
        "        self.lin2 = nn.Linear(30, 20)\n",
        "        self.drop_layer = nn.Dropout(p=0.4)\n",
        "        self.lin3 = nn.Linear(20, 10)\n",
        "        self.lin4 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.drop_layer(x)\n",
        "        x = self.lin3(x)\n",
        "        return F.softmax(self.lin4(x))\n",
        "    \n",
        "model8 = Task8(BIGRAM_VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "audcAg5foR1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model8 = model8.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(model6.parameters(), lr = 0.05)\n",
        "patience = 4\n",
        "best_loss = 0.\n",
        "for epoch in range(20):\n",
        "    tic = time.time()\n",
        "    for instance, label in data:\n",
        "        model8.zero_grad()\n",
        "        vec = Variable(make_bow_vector(instance, bigrm_to_ix)).to(device)\n",
        "        label = Variable(make_target(label)).to(device)\n",
        "        probs = model8(vec) # forward pass\n",
        "        loss = loss_function(probs, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    toc = time.time()\n",
        "    print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n",
        "    \n",
        "    if loss.data < best_loss:\n",
        "        best_loss = loss.data\n",
        "        patience = 4\n",
        "    else:\n",
        "        patience -=1 \n",
        "        if patience == 0:\n",
        "            break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0P2qhX2w9qc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_MSE_Hinge(model, isGpu, loss_function):\n",
        "    if isGpu:\n",
        "        model = model.to(device)\n",
        "        \n",
        "    opt = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
        "    # the training loop\n",
        "    patience = 5\n",
        "    for epoch in range(30):\n",
        "        tic = time.time()\n",
        "        for batch_idx, (instance, label) in enumerate(train_loader):\n",
        "            # get the training data\n",
        "            model.zero_grad()\n",
        "            label = label.long()\n",
        "            probs = model(instance) # forward pass\n",
        "            label = make_one_hot(label).to(device)\n",
        "            loss = loss_function(probs, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        toc = time.time()\n",
        "        print('EPOCH: {}, CURRENT LOSS: {}, TIME TAKEN: {}'.format(epoch, loss.data, (toc-tic)))\n",
        "        if epoch == 0:\n",
        "            best_loss = loss.data\n",
        "            continue\n",
        "        if loss.data < best_loss:\n",
        "            best_loss = loss.data\n",
        "            patience = 5\n",
        "        else:\n",
        "            patience -=1 \n",
        "            if patience == 0:\n",
        "                break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fs25mAqmxVMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "146580cf-c03e-47a6-cce7-a406c9ae52fe"
      },
      "cell_type": "code",
      "source": [
        "train_MSE_Hinge(model7C, True, nn.HingeEmbeddingLoss())\n",
        "validate(model7C)\n",
        "torch.save(model7C, 'Task7C.mdl')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, CURRENT LOSS: 0.6000000238418579, TIME TAKEN: 2.444589853286743\n",
            "EPOCH: 1, CURRENT LOSS: 0.7000000476837158, TIME TAKEN: 2.2382571697235107\n",
            "in else\n",
            "EPOCH: 2, CURRENT LOSS: 0.6333333849906921, TIME TAKEN: 2.226335287094116\n",
            "in else\n",
            "EPOCH: 3, CURRENT LOSS: 0.6333333849906921, TIME TAKEN: 2.230898380279541\n",
            "in else\n",
            "EPOCH: 4, CURRENT LOSS: 0.6666666865348816, TIME TAKEN: 2.2563865184783936\n",
            "in else\n",
            "EPOCH: 5, CURRENT LOSS: 0.6333333849906921, TIME TAKEN: 2.2417232990264893\n",
            "in else\n",
            "accuracy: 0.3378\n",
            "precision: 0.11012782694198624\n",
            "recall: 0.04447974583002383\n",
            "f1-score: 0.06336633663366337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Task7C. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}